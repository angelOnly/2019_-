{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import json\n",
    "import jieba\n",
    "import codecs\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.externals import joblib\n",
    "import re\n",
    "from scipy.sparse import vstack\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将新闻内容以。划分，取包含 company_name 的句子，构成训练文本数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40000it [00:02, 16901.38it/s]\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "with open('../data/coreEntityEmotion_train.txt', encoding='utf-8') as f:\n",
    "    for l in tqdm(f):\n",
    "        a = json.loads(l.strip())\n",
    "        item = {}\n",
    "        item['content'] = a['title'] + '。' + a['content']\n",
    "        \n",
    "        temp = {}\n",
    "        for c in a['coreEntityEmotions']:\n",
    "            temp[c['entity']] = c['emotion']\n",
    "        item['coreEntityEmotions'] = temp\n",
    "        \n",
    "        data[a['newsId']] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open('../output/train_data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = codecs.open('../output/train_data.json', 'r', encoding='utf-8')\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_text(text):\n",
    "    re_tag0 = re.compile('</?\\w+[^>]*>')  # HTML标签\n",
    "    re_tag1 = re.compile(r'http://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',re.S)\n",
    "    re_tag2 = re.compile(r'https://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',re.S)\n",
    "    re_tag3 = re.compile('(?<=\\>).*?(?=\\<)')\n",
    "    re_tag4 = re.compile('购买链接')\n",
    "    re_tag5 = re.compile('京东：')\n",
    "    re_tag6 = re.compile('淘宝：')\n",
    "    re_tag7 = re.compile(r'\\d.*?w|\\d.*?v|\\d.*?a|\\d.*?亿元|\\d.*?元|\\d.*?plus')\n",
    "    new_text = re.sub(re_tag0,\"\",text)\n",
    "    new_text = re.sub(re_tag1,\"\",new_text)\n",
    "    new_text = re.sub(re_tag2,\"\",new_text)\n",
    "    new_text = re.sub(re_tag3,\"\",new_text)\n",
    "    new_text = re.sub(re_tag4,\"\",new_text)\n",
    "    new_text = re.sub(re_tag5,\"\",new_text)\n",
    "    new_text = re.sub(re_tag6,\"\",new_text)\n",
    "    new_text = re.sub(re_tag7, \"\", new_text)\n",
    "    new_text = re.sub(\"-+\", \"-\", new_text)  # 合并-\n",
    "    new_text = re.sub(\"———+\", \"——\", new_text)  # 合并-\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(read_data, save_data, save_data2):\n",
    "    \"\"\"\n",
    "    第2步：\n",
    "    将新闻内容以。划分，取包含 company_name 的句子，构成训练文本数据\n",
    "    :param read_data:           读入数据\n",
    "    :param save_data:           保存可以训练的数据（通过主体是否再句子中，取出句子不为空的数据） 2warning_sentence.csv\n",
    "    :param save_data2:          保存bad数据  2warning_sen_bad.csv\n",
    "    :param save_data3:          保存通过主体是否再句子中，但取出句子为空的数据 2warning_sen_none.csv\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    with codecs.open(read_data, 'r', 'utf-8') as f, open(save_data, 'w') as wf, open(save_data2, 'w') as wf2:\n",
    "        num = 0              # 计数，成功写入\n",
    "        bad = 0              # 计数，失败\n",
    "        data = json.load(f)\n",
    "        for newsId, item in data.items():\n",
    "            text = item['content']              # 存放训练数据\n",
    "            content_list = text.split('。')     # 以。划分句子\n",
    "            entity_list = item['coreEntityEmotions']\n",
    "            for entity,emotion in entity_list.items(): #3d，工业，机器视觉\n",
    "                try:\n",
    "                    content = ''\n",
    "                    for sentence in content_list:\n",
    "                        # 如果文中名字（manual_ori_company）在该句子中\n",
    "                        sentence = filter_text(sentence)\n",
    "                        sentence = sentence.replace('\\n', '')\n",
    "                        if entity in sentence:\n",
    "                            if len(sentence) < 300:\n",
    "                                # 将文本数据中的英文符号 : ' \"  转换成 中文符号 ：‘”   另外\\ 转换成\\\\ 防止解析json出错\n",
    "                                sentence = sentence.replace(':', '：').replace('\\'', '‘') \\\n",
    "                                .replace('\\\"', '“').replace('\\\\', '\\\\\\\\')\n",
    "                            else:\n",
    "                                # 找到主体所在句子的位置\n",
    "                                index = sentence.find(entity)\n",
    "                                end = index + len(entity) + 80\n",
    "                                sentence = sentence[index:end]\n",
    "                             # 不让。出现在content1的首位置\n",
    "                            if content == '':\n",
    "                                content = sentence\n",
    "                            else:\n",
    "                                content = content + '。' + sentence\n",
    "                            # 判断取出的content是否为空\n",
    "                            if len(content) == 0:\n",
    "                                continue\n",
    "                            else:\n",
    "                                wf.write(newsId + '\\t' + content + '\\t' + entity + '\\t' + emotion + '\\n')\n",
    "                                num += 1\n",
    "#                                 print('\\n num:', num)\n",
    "                except:\n",
    "                    import traceback\n",
    "                    bad += 1\n",
    "                    print(key)\n",
    "                    wf2.write(newsId + '\\t' + text + '\\t' + entity + '\\t' + emotion + '\\n')\n",
    "                    print(traceback.format_exc())\n",
    "                    print('bad:', bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data = '../output/train_data.json'\n",
    "save_data = '../output/entity_sentence.csv'\n",
    "save_data2 = '../output/entity_bad_sentence.csv'\n",
    "make_data(read_data, save_data, save_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from math import sqrt\n",
    "\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = '../output/small_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_data, 'r', encoding='utf-8') as rf, open(small_data, 'w', encoding='utf-8') as wf:\n",
    "    num = 0   # count\n",
    "    for line in rf:\n",
    "        line = line.strip('\\n')\n",
    "        if num < 10000:\n",
    "            wf.write(line + '\\n')\n",
    "            num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newsId</th>\n",
       "      <th>content</th>\n",
       "      <th>entity</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>574c9492</td>\n",
       "      <td>自《阿丽塔：战斗天使》上映以来，就备受网友们的关注，因为这是卡梅隆自《阿凡达》之后的又一部特...</td>\n",
       "      <td>阿丽塔</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>574c9492</td>\n",
       "      <td>自《阿丽塔：战斗天使》上映以来，就备受网友们的关注，因为这是卡梅隆自《阿凡达》之后的又一部特...</td>\n",
       "      <td>阿丽塔</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>574c9492</td>\n",
       "      <td>自《阿丽塔：战斗天使》上映以来，就备受网友们的关注，因为这是卡梅隆自《阿凡达》之后的又一部特...</td>\n",
       "      <td>阿丽塔</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>574c9492</td>\n",
       "      <td>自《阿丽塔：战斗天使》上映以来，就备受网友们的关注，因为这是卡梅隆自《阿凡达》之后的又一部特...</td>\n",
       "      <td>阿丽塔</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>574c9492</td>\n",
       "      <td>日票房不足100万，卡梅隆尽力了，他已经跌下神坛</td>\n",
       "      <td>卡梅隆</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        newsId                                            content entity  \\\n",
       "9995  574c9492  自《阿丽塔：战斗天使》上映以来，就备受网友们的关注，因为这是卡梅隆自《阿凡达》之后的又一部特...    阿丽塔   \n",
       "9996  574c9492  自《阿丽塔：战斗天使》上映以来，就备受网友们的关注，因为这是卡梅隆自《阿凡达》之后的又一部特...    阿丽塔   \n",
       "9997  574c9492  自《阿丽塔：战斗天使》上映以来，就备受网友们的关注，因为这是卡梅隆自《阿凡达》之后的又一部特...    阿丽塔   \n",
       "9998  574c9492  自《阿丽塔：战斗天使》上映以来，就备受网友们的关注，因为这是卡梅隆自《阿凡达》之后的又一部特...    阿丽塔   \n",
       "9999  574c9492                           日票房不足100万，卡梅隆尽力了，他已经跌下神坛    卡梅隆   \n",
       "\n",
       "     emotion  \n",
       "9995     NEG  \n",
       "9996     NEG  \n",
       "9997     NEG  \n",
       "9998     NEG  \n",
       "9999     NEG  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(small_data, sep='\\t', names=['newsId', 'content','entity', 'emotion'])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newsId</th>\n",
       "      <th>content</th>\n",
       "      <th>entity</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>527</td>\n",
       "      <td>9181</td>\n",
       "      <td>1203</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>d6cb209a</td>\n",
       "      <td>jennie出席香奈儿秀场连衣裙秀身材，这腰谁扛得住</td>\n",
       "      <td>美国</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>186</td>\n",
       "      <td>3</td>\n",
       "      <td>143</td>\n",
       "      <td>4890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          newsId                     content entity emotion\n",
       "count      10000                       10000  10000   10000\n",
       "unique       527                        9181   1203       3\n",
       "top     d6cb209a  jennie出席香奈儿秀场连衣裙秀身材，这腰谁扛得住     美国     POS\n",
       "freq         186                           3    143    4890"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 4 columns):\n",
      "newsId     10000 non-null object\n",
      "content    10000 non-null object\n",
      "entity     10000 non-null object\n",
      "emotion    10000 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 312.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_dic(label):\n",
    "    if label == 'POS':\n",
    "        return 1\n",
    "    elif label == 'NORM':\n",
    "        return 0\n",
    "    elif label == 'NEG':\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_dic(label):\n",
    "    if label == 'POS':\n",
    "        return 1\n",
    "    elif label == 'NORM':\n",
    "        return 0\n",
    "    elif label == 'NEG':\n",
    "        return -1\n",
    "df[\"emotion\"] = df[\"emotion\"].apply(label_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newsId</th>\n",
       "      <th>content</th>\n",
       "      <th>entity</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>ff011e44</td>\n",
       "      <td>近日，《elle·3月》封面曝光，贾静雯担纲入镜，照片中的她大玩搞怪风之余，还大谈中年女性心...</td>\n",
       "      <td>elle·3月</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>574c9492</td>\n",
       "      <td>自《阿丽塔：战斗天使》上映以来，就备受网友们的关注，因为这是卡梅隆自《阿凡达》之后的又一部特...</td>\n",
       "      <td>阿丽塔</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>574c9492</td>\n",
       "      <td>自《阿丽塔：战斗天使》上映以来，就备受网友们的关注，因为这是卡梅隆自《阿凡达》之后的又一部特...</td>\n",
       "      <td>阿丽塔</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>574c9492</td>\n",
       "      <td>自《阿丽塔：战斗天使》上映以来，就备受网友们的关注，因为这是卡梅隆自《阿凡达》之后的又一部特...</td>\n",
       "      <td>阿丽塔</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>574c9492</td>\n",
       "      <td>自《阿丽塔：战斗天使》上映以来，就备受网友们的关注，因为这是卡梅隆自《阿凡达》之后的又一部特...</td>\n",
       "      <td>阿丽塔</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>574c9492</td>\n",
       "      <td>自《阿丽塔：战斗天使》上映以来，就备受网友们的关注，因为这是卡梅隆自《阿凡达》之后的又一部特...</td>\n",
       "      <td>阿丽塔</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>574c9492</td>\n",
       "      <td>自《阿丽塔：战斗天使》上映以来，就备受网友们的关注，因为这是卡梅隆自《阿凡达》之后的又一部特...</td>\n",
       "      <td>阿丽塔</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>574c9492</td>\n",
       "      <td>自《阿丽塔：战斗天使》上映以来，就备受网友们的关注，因为这是卡梅隆自《阿凡达》之后的又一部特...</td>\n",
       "      <td>阿丽塔</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>574c9492</td>\n",
       "      <td>自《阿丽塔：战斗天使》上映以来，就备受网友们的关注，因为这是卡梅隆自《阿凡达》之后的又一部特...</td>\n",
       "      <td>阿丽塔</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>574c9492</td>\n",
       "      <td>日票房不足100万，卡梅隆尽力了，他已经跌下神坛</td>\n",
       "      <td>卡梅隆</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        newsId                                            content   entity  \\\n",
       "9990  ff011e44  近日，《elle·3月》封面曝光，贾静雯担纲入镜，照片中的她大玩搞怪风之余，还大谈中年女性心...  elle·3月   \n",
       "9991  574c9492  自《阿丽塔：战斗天使》上映以来，就备受网友们的关注，因为这是卡梅隆自《阿凡达》之后的又一部特...      阿丽塔   \n",
       "9992  574c9492  自《阿丽塔：战斗天使》上映以来，就备受网友们的关注，因为这是卡梅隆自《阿凡达》之后的又一部特...      阿丽塔   \n",
       "9993  574c9492  自《阿丽塔：战斗天使》上映以来，就备受网友们的关注，因为这是卡梅隆自《阿凡达》之后的又一部特...      阿丽塔   \n",
       "9994  574c9492  自《阿丽塔：战斗天使》上映以来，就备受网友们的关注，因为这是卡梅隆自《阿凡达》之后的又一部特...      阿丽塔   \n",
       "9995  574c9492  自《阿丽塔：战斗天使》上映以来，就备受网友们的关注，因为这是卡梅隆自《阿凡达》之后的又一部特...      阿丽塔   \n",
       "9996  574c9492  自《阿丽塔：战斗天使》上映以来，就备受网友们的关注，因为这是卡梅隆自《阿凡达》之后的又一部特...      阿丽塔   \n",
       "9997  574c9492  自《阿丽塔：战斗天使》上映以来，就备受网友们的关注，因为这是卡梅隆自《阿凡达》之后的又一部特...      阿丽塔   \n",
       "9998  574c9492  自《阿丽塔：战斗天使》上映以来，就备受网友们的关注，因为这是卡梅隆自《阿凡达》之后的又一部特...      阿丽塔   \n",
       "9999  574c9492                           日票房不足100万，卡梅隆尽力了，他已经跌下神坛      卡梅隆   \n",
       "\n",
       "      emotion  \n",
       "9990        1  \n",
       "9991       -1  \n",
       "9992       -1  \n",
       "9993       -1  \n",
       "9994       -1  \n",
       "9995       -1  \n",
       "9996       -1  \n",
       "9997       -1  \n",
       "9998       -1  \n",
       "9999       -1  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../output/train_df.csv\", index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型升级和跨越发展！誉洋3d机器视觉引发展会参观热潮在大连誉洋工业智能的展位，机器人自动抓取物件让人眼前一亮',\n",
       " '无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型升级和跨越发展！誉洋3d机器视觉引发展会参观热潮在大连誉洋工业智能的展位，机器人自动抓取物件让人眼前一亮。机器人在3d视觉的引导下精准定位杂乱无序的目标，并实现准确快速抓取，整个过程井然有序，无需任何人工干预']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = df[\"content\"].tolist()\n",
    "review[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[\"emotion\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[98, 150, 224, 260, 333, 424, 44, 126, 225, 298]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = [len(x) for x in review]\n",
    "lengths[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5596, 5525, 5491, 5450, 5402, 5305, 5225, 5111, 5069, 5032, 4966,\n",
       "       4928, 4819, 4714, 4645, 4617, 4582, 4567, 4507, 4441, 4403, 4373,\n",
       "       4334, 4303, 4236, 4198, 4138, 4098, 4057, 4016, 3992, 3946, 3911,\n",
       "       3859, 3846, 3809, 3756, 3722, 3697, 3687, 3673, 3665, 3629, 3619,\n",
       "       3617, 3568, 3550, 3545, 3531, 3527, 3515, 3471, 3452, 3441, 3440,\n",
       "       3427, 3422, 3402, 3391, 3357, 3354, 3352, 3331, 3313, 3307, 3282,\n",
       "       3268, 3256, 3228, 3201, 3197, 3190, 3185, 3176, 3158, 3153, 3139,\n",
       "       3126, 3111, 3110, 3102, 3068, 3030, 3025, 3024, 2997, 2988, 2977,\n",
       "       2976, 2973, 2956, 2951, 2950, 2946, 2945, 2939, 2923, 2912, 2912,\n",
       "       2888, 2886, 2882, 2875, 2854, 2854, 2854, 2853, 2833, 2814, 2810,\n",
       "       2808, 2796, 2781, 2780, 2772, 2762, 2760, 2752, 2750, 2743, 2735,\n",
       "       2734, 2731, 2728, 2721, 2715, 2709, 2698, 2696, 2689, 2674, 2658,\n",
       "       2656, 2652, 2647, 2642, 2632, 2628, 2626, 2615, 2611, 2600, 2598,\n",
       "       2598, 2596, 2590, 2571, 2565, 2560, 2559, 2558, 2556, 2549, 2531,\n",
       "       2529, 2525, 2519, 2517, 2507, 2502, 2493, 2488, 2485, 2481, 2478,\n",
       "       2471, 2471, 2460, 2460, 2457, 2450, 2449, 2439, 2439, 2439, 2435,\n",
       "       2421, 2418, 2417, 2407, 2407, 2405, 2401, 2400, 2396, 2395, 2384,\n",
       "       2382, 2380, 2377, 2375, 2371, 2369, 2368, 2355, 2350, 2348, 2347,\n",
       "       2339, 2336])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = sorted(lengths, key=lambda x: x, reverse=True)\n",
    "lengths = np.array(lengths)\n",
    "lengths[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_len(x):\n",
    "    if len(x)<=1500:\n",
    "        return 1500\n",
    "    elif len(x)>1500 and len(x)<=2000:\n",
    "        return 2000\n",
    "    elif len(x)>2000 and len(x)<=3000:\n",
    "        return 3000\n",
    "    else:\n",
    "        return 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1 = df.copy()\n",
    "df_test1[\"len\"] = df_test1[\"content\"].apply(cut_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newsId</th>\n",
       "      <th>content</th>\n",
       "      <th>entity</th>\n",
       "      <th>emotion</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4e36d02a</td>\n",
       "      <td>无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型...</td>\n",
       "      <td>3d</td>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4e36d02a</td>\n",
       "      <td>无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型...</td>\n",
       "      <td>3d</td>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e36d02a</td>\n",
       "      <td>无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型...</td>\n",
       "      <td>3d</td>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4e36d02a</td>\n",
       "      <td>无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型...</td>\n",
       "      <td>3d</td>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4e36d02a</td>\n",
       "      <td>无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型...</td>\n",
       "      <td>3d</td>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     newsId                                            content entity  \\\n",
       "0  4e36d02a  无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型...     3d   \n",
       "1  4e36d02a  无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型...     3d   \n",
       "2  4e36d02a  无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型...     3d   \n",
       "3  4e36d02a  无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型...     3d   \n",
       "4  4e36d02a  无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型...     3d   \n",
       "\n",
       "   emotion   len  \n",
       "0        1  1500  \n",
       "1        1  1500  \n",
       "2        1  1500  \n",
       "3        1  1500  \n",
       "4        1  1500  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Number of words in the text ##\n",
    "df_test[\"len\"] = df_test[\"content\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.34470</td>\n",
       "      <td>475.256200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.71731</td>\n",
       "      <td>586.948842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.00000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1%</th>\n",
       "      <td>-1.00000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>-1.00000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>122.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>282.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>868.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1105.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1624.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>2886.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>5596.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           emotion           len\n",
       "count  10000.00000  10000.000000\n",
       "mean       0.34470    475.256200\n",
       "std        0.71731    586.948842\n",
       "min       -1.00000      5.000000\n",
       "1%        -1.00000     17.000000\n",
       "10%       -1.00000     42.000000\n",
       "25%        0.00000    122.000000\n",
       "50%        0.00000    282.000000\n",
       "75%        1.00000    587.000000\n",
       "85%        1.00000    868.000000\n",
       "90%        1.00000   1105.300000\n",
       "95%        1.00000   1624.050000\n",
       "99%        1.00000   2886.020000\n",
       "max        1.00000   5596.000000"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe([0.01,0.1,0.25,.5,.75,.85,.90,.95,.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a4fde9940>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(x='len', data=df_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_freq(data):\n",
    "    ncount = len(data)\n",
    "\n",
    "    ax2=ax.twinx()\n",
    "\n",
    "    ax2.yaxis.tick_left()\n",
    "    ax.yaxis.tick_right()\n",
    "\n",
    "    ax.yaxis.set_label_position('right')\n",
    "    ax2.yaxis.set_label_position('left')\n",
    "\n",
    "    ax2.set_ylabel('Frequency [%]')\n",
    "\n",
    "    for p in ax.patches:\n",
    "        x=p.get_bbox().get_points()[:,0]\n",
    "        y=p.get_bbox().get_points()[1,1]\n",
    "        ax.annotate('{:.1f}%'.format(100.*y/ncount), (x.mean(), y), \n",
    "                ha='center', va='bottom')\n",
    "\n",
    "    ax2.set_ylim(0,100)\n",
    "    ax2.grid(None)\n",
    "    \n",
    "ax = sns.countplot(x = df_test1.len ,palette=\"Set3\")\n",
    "sns.set(font_scale=1.5)\n",
    "ax.set_ylim(top = 150000)\n",
    "ax.set_xlabel(' ')\n",
    "ax.set_ylabel(' ')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10,5)\n",
    "ax.set_ylim(top=160000)\n",
    "\n",
    "add_freq(df_test1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置参数\n",
    "\n",
    "class TrainingConfig(object):\n",
    "    epoches = 10\n",
    "    evaluateEvery = 100\n",
    "    checkpointEvery = 100\n",
    "    learningRate = 0.001\n",
    "    \n",
    "    \n",
    "class ModelConfig(object):\n",
    "    embeddingSize = 200\n",
    "    \n",
    "    filters = 128  # 内层一维卷积核的数量，外层卷积核的数量应该等于embeddingSize，因为要确保每个layer后的输出维度和输入维度是一致的。\n",
    "    numHeads = 8  # Attention 的头数\n",
    "    numBlocks = 1  # 设置transformer block的数量\n",
    "    epsilon = 1e-8  # LayerNorm 层中的最小除数\n",
    "    keepProp = 0.9  # multi head attention 中的dropout\n",
    "    \n",
    "    dropoutKeepProb = 0.5 # 全连接层的dropout\n",
    "    l2RegLambda = 0.0\n",
    "    \n",
    "    \n",
    "class Config(object):\n",
    "    sequenceLength = 1500  # 取了所有序列长度的均值\n",
    "    batchSize = 128\n",
    "    \n",
    "    dataSource = \"../output/train_df.csv\"\n",
    "    \n",
    "    numClasses = 2\n",
    "    \n",
    "    rate = 0.8  # 训练集的比例\n",
    "    \n",
    "    training = TrainingConfig()\n",
    "    \n",
    "    model = ModelConfig()\n",
    "\n",
    "    \n",
    "# 实例化配置参数对象\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  data finish\n",
      "500  data finish\n",
      "1000  data finish\n",
      "1500  data finish\n",
      "2000  data finish\n",
      "2500  data finish\n",
      "3000  data finish\n",
      "3500  data finish\n",
      "4000  data finish\n",
      "4500  data finish\n",
      "5000  data finish\n",
      "5500  data finish\n",
      "6000  data finish\n",
      "6500  data finish\n",
      "7000  data finish\n",
      "7500  data finish\n",
      "8000  data finish\n",
      "8500  data finish\n",
      "9000  data finish\n",
      "9500  data finish\n",
      "10000  data finish\n",
      "连过不存在于词向量中\n",
      "指为不存在于词向量中\n",
      "已向不存在于词向量中\n",
      "看完不存在于词向量中\n",
      "应属不存在于词向量中\n",
      "改出不存在于词向量中\n",
      "较快不存在于词向量中\n",
      "着名不存在于词向量中\n",
      "种得不存在于词向量中\n",
      "大场不存在于词向量中\n",
      "很美不存在于词向量中\n",
      "后端不存在于词向量中\n",
      "仍以不存在于词向量中\n",
      "官全不存在于词向量中\n",
      "回中不存在于词向量中\n",
      "赶去不存在于词向量中\n",
      "归到不存在于词向量中\n",
      "理出不存在于词向量中\n",
      "之举不存在于词向量中\n",
      "为直不存在于词向量中\n",
      "听清不存在于词向量中\n",
      "起至不存在于词向量中\n",
      "拿起不存在于词向量中\n",
      "自股不存在于词向量中\n",
      "熟到不存在于词向量中\n",
      "体用不存在于词向量中\n",
      "解了不存在于词向量中\n",
      "特在不存在于词向量中\n",
      "没给不存在于词向量中\n",
      "中韩不存在于词向量中\n",
      "党心不存在于词向量中\n",
      "其钱不存在于词向量中\n",
      "小场不存在于词向量中\n",
      "亚都不存在于词向量中\n",
      "首月不存在于词向量中\n",
      "想靠不存在于词向量中\n",
      "听完不存在于词向量中\n",
      "所讲不存在于词向量中\n",
      "这季不存在于词向量中\n",
      "流到不存在于词向量中\n",
      "收得不存在于词向量中\n",
      "vh不存在于词向量中\n",
      "一划不存在于词向量中\n",
      "设于不存在于词向量中\n",
      "做分不存在于词向量中\n",
      "所应不存在于词向量中\n",
      "抢得不存在于词向量中\n",
      "坐得不存在于词向量中\n",
      "拍去不存在于词向量中\n",
      "所具不存在于词向量中\n",
      "合起不存在于词向量中\n",
      "没数不存在于词向量中\n"
     ]
    }
   ],
   "source": [
    "# 数据预处理的类，生成训练集和测试集\n",
    "\n",
    "class Dataset(object):\n",
    "    def __init__(self, config):\n",
    "        self._dataSource = config.dataSource\n",
    "        \n",
    "        self._sequenceLength = config.sequenceLength  # 每条输入的序列处理为定长\n",
    "        self._embeddingSize = config.model.embeddingSize\n",
    "        self._batchSize = config.batchSize\n",
    "        self._rate = config.rate\n",
    "        \n",
    "        self.trainReviews = []\n",
    "        self.trainLabels = []\n",
    "        \n",
    "        self.evalReviews = []\n",
    "        self.evalLabels = []\n",
    "        \n",
    "        self.wordEmbedding =None\n",
    "        \n",
    "        self._wordToIndex = {}\n",
    "        self._indexToWord = {}\n",
    "        \n",
    "    def _readData(self, filePath):\n",
    "        \"\"\"\n",
    "        从csv文件中读取数据集\n",
    "        \"\"\"\n",
    "        \n",
    "        df = pd.read_csv(filePath, sep='\\t', names=['newsId', 'content','entity', 'emotion'])\n",
    "        review = df[\"content\"].tolist()\n",
    "        \n",
    "        def label_dic(label):\n",
    "            if label == 'POS':\n",
    "                return 1\n",
    "            elif label == 'NORM':\n",
    "                return 0\n",
    "            elif label == 'NEG':\n",
    "                return -1\n",
    "            \n",
    "        df[\"emotion\"] = df[\"emotion\"].apply(label_dic)\n",
    "        labels = df[\"emotion\"].tolist()\n",
    "        \n",
    "        import jieba\n",
    "        files = os.listdir('../字典')\n",
    "        for file_name in files:\n",
    "            jieba.load_userdict('../字典/' + file_name)\n",
    "        jieba.load_userdict('../runs/entity.txt')\n",
    "\n",
    "        stop_words = []\n",
    "        with open('../data/stop_words.txt', 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                line = line.replace(\"\\n\", \"\")\n",
    "                stop_words.append(line)\n",
    "\n",
    "        all_docs = []\n",
    "        i = 0\n",
    "        for data in review:\n",
    "            words = jieba.cut(data)\n",
    "            words = filter(lambda x: x not in stop_words, words)\n",
    "            all_docs.append(list(words))\n",
    "            if i % 500 == 0:\n",
    "                print(i, ' data finish')\n",
    "            i += 1\n",
    "\n",
    "        return all_docs, labels\n",
    "\n",
    "    def _reviewProcess(self, review, sequenceLength, wordToIndex):\n",
    "        \"\"\"\n",
    "        将数据集中的每条评论用index表示\n",
    "        wordToIndex中“pad”对应的index为0\n",
    "        \"\"\"\n",
    "        \n",
    "        reviewVec = np.zeros((sequenceLength))\n",
    "        sequenceLen = sequenceLength\n",
    "        \n",
    "        # 判断当前的序列是否小于定义的固定序列长度\n",
    "        if len(review) < sequenceLength:\n",
    "            sequenceLen = len(review)\n",
    "            \n",
    "        for i in range(sequenceLen):\n",
    "            if review[i] in wordToIndex:\n",
    "                reviewVec[i] = wordToIndex[review[i]]\n",
    "            else:\n",
    "                reviewVec[i] = wordToIndex[\"UNK\"]\n",
    "\n",
    "        return reviewVec\n",
    "\n",
    "    def _genTrainEvalData(self, x, y, rate):\n",
    "        \"\"\"\n",
    "        生成训练集和验证集\n",
    "        \"\"\"\n",
    "        \n",
    "        reviews = []\n",
    "        labels = []\n",
    "        \n",
    "        # 遍历所有的文本，将文本中的词转换成index表示\n",
    "        for i in range(len(x)):\n",
    "            reviewVec = self._reviewProcess(x[i], self._sequenceLength, self._wordToIndex)\n",
    "            reviews.append(reviewVec)\n",
    "            \n",
    "            labels.append([y[i]])\n",
    "            \n",
    "        trainIndex = int(len(x) * rate)\n",
    "        \n",
    "        trainReviews = np.asarray(reviews[:trainIndex], dtype=\"int64\")\n",
    "        trainLabels = np.array(labels[:trainIndex], dtype=\"float32\")\n",
    "        \n",
    "        evalReviews = np.asarray(reviews[trainIndex:], dtype=\"int64\")\n",
    "        evalLabels = np.array(labels[trainIndex:], dtype=\"float32\")\n",
    "\n",
    "        return trainReviews, trainLabels, evalReviews, evalLabels\n",
    "        \n",
    "    def _genVocabulary(self, reviews):\n",
    "        \"\"\"\n",
    "        生成词向量和词汇-索引映射字典，可以用全数据集\n",
    "        \"\"\"\n",
    "        \n",
    "        allWords = [word for review in reviews for word in review]\n",
    "        \n",
    "        wordCount = Counter(allWords)  # 统计词频\n",
    "        sortWordCount = sorted(wordCount.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # 去除低频词\n",
    "        words = [item[0] for item in sortWordCount if item[1] >= 2]\n",
    "        \n",
    "        vocab, wordEmbedding = self._getWordEmbedding(words)\n",
    "        self.wordEmbedding = wordEmbedding\n",
    "        \n",
    "        self._wordToIndex = dict(zip(vocab, list(range(len(vocab)))))\n",
    "        self._indexToWord = dict(zip(list(range(len(vocab))), vocab))\n",
    "        \n",
    "        # 将词汇-索引映射表保存为json数据，之后做inference时直接加载来处理数据\n",
    "        with open(\"../output/wordToIndex.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(self._wordToIndex, f)\n",
    "        \n",
    "        with open(\"../output/indexToWord.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(self._indexToWord, f)\n",
    "            \n",
    "    def _getWordEmbedding(self, words):\n",
    "        \"\"\"\n",
    "        按照我们的数据集中的单词取出预训练好的word2vec中的词向量\n",
    "        \"\"\"\n",
    "        from gensim.models import FastText\n",
    "        wordVec = FastText.load('../runs/fasttext_model')\n",
    "        vocab = []\n",
    "        wordEmbedding = []\n",
    "        \n",
    "        # 添加 \"pad\" 和 \"UNK\", \n",
    "        vocab.append(\"pad\")\n",
    "        vocab.append(\"UNK\")\n",
    "        wordEmbedding.append(np.zeros(self._embeddingSize))\n",
    "        wordEmbedding.append(np.random.randn(self._embeddingSize))\n",
    "        \n",
    "        for word in words:\n",
    "            try:\n",
    "                vector = wordVec.wv[word]\n",
    "                vocab.append(word)\n",
    "                wordEmbedding.append(vector)\n",
    "            except:\n",
    "                print(word + \"不存在于词向量中\")\n",
    "                \n",
    "        return vocab, np.array(wordEmbedding)\n",
    "            \n",
    "    def dataGen(self):\n",
    "        \"\"\"\n",
    "        初始化训练集和验证集\n",
    "        \"\"\"\n",
    "        # 初始化数据集\n",
    "        reviews, labels = self._readData(self._dataSource)\n",
    "        \n",
    "        # 初始化词汇-索引映射表和词向量矩阵\n",
    "        self._genVocabulary(reviews)\n",
    "        \n",
    "        # 初始化训练集和测试集\n",
    "        trainReviews, trainLabels, evalReviews, evalLabels = self._genTrainEvalData(reviews, labels, self._rate)\n",
    "        self.trainReviews = trainReviews\n",
    "        self.trainLabels = trainLabels\n",
    "        \n",
    "        self.evalReviews = evalReviews\n",
    "        self.evalLabels = evalLabels\n",
    "        \n",
    "data = Dataset(config)\n",
    "data.dataGen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23526, 200)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.wordEmbedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.772068</td>\n",
       "      <td>1.923703</td>\n",
       "      <td>1.379893</td>\n",
       "      <td>0.483076</td>\n",
       "      <td>0.826718</td>\n",
       "      <td>-0.062425</td>\n",
       "      <td>0.289548</td>\n",
       "      <td>0.457742</td>\n",
       "      <td>0.640200</td>\n",
       "      <td>-0.876724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426017</td>\n",
       "      <td>-1.258112</td>\n",
       "      <td>-0.547281</td>\n",
       "      <td>-0.609702</td>\n",
       "      <td>-0.957129</td>\n",
       "      <td>0.066992</td>\n",
       "      <td>1.802548</td>\n",
       "      <td>-0.343936</td>\n",
       "      <td>0.228859</td>\n",
       "      <td>0.889228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.390790</td>\n",
       "      <td>-0.929125</td>\n",
       "      <td>-2.371427</td>\n",
       "      <td>-1.126142</td>\n",
       "      <td>-0.232861</td>\n",
       "      <td>-0.555668</td>\n",
       "      <td>0.060788</td>\n",
       "      <td>-2.067189</td>\n",
       "      <td>0.708972</td>\n",
       "      <td>1.869089</td>\n",
       "      <td>...</td>\n",
       "      <td>1.769296</td>\n",
       "      <td>0.607791</td>\n",
       "      <td>1.685267</td>\n",
       "      <td>0.462870</td>\n",
       "      <td>1.235561</td>\n",
       "      <td>2.705509</td>\n",
       "      <td>-3.699732</td>\n",
       "      <td>0.136413</td>\n",
       "      <td>1.322007</td>\n",
       "      <td>0.485764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.256993</td>\n",
       "      <td>-0.627401</td>\n",
       "      <td>-0.376660</td>\n",
       "      <td>-0.145329</td>\n",
       "      <td>-0.640091</td>\n",
       "      <td>-0.257066</td>\n",
       "      <td>-0.007209</td>\n",
       "      <td>0.066371</td>\n",
       "      <td>-0.923578</td>\n",
       "      <td>0.741953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378577</td>\n",
       "      <td>-0.465361</td>\n",
       "      <td>0.712872</td>\n",
       "      <td>-0.108740</td>\n",
       "      <td>0.223569</td>\n",
       "      <td>0.042677</td>\n",
       "      <td>-1.303379</td>\n",
       "      <td>-0.874297</td>\n",
       "      <td>0.215704</td>\n",
       "      <td>-0.256057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.778642</td>\n",
       "      <td>-0.788620</td>\n",
       "      <td>0.440488</td>\n",
       "      <td>0.910248</td>\n",
       "      <td>0.421461</td>\n",
       "      <td>0.251527</td>\n",
       "      <td>0.307918</td>\n",
       "      <td>-0.429128</td>\n",
       "      <td>-0.015830</td>\n",
       "      <td>2.231030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.868681</td>\n",
       "      <td>0.239313</td>\n",
       "      <td>0.347212</td>\n",
       "      <td>-0.594535</td>\n",
       "      <td>0.660311</td>\n",
       "      <td>0.547517</td>\n",
       "      <td>-0.272696</td>\n",
       "      <td>-0.192027</td>\n",
       "      <td>-0.037123</td>\n",
       "      <td>-1.403011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1 -0.772068  1.923703  1.379893  0.483076  0.826718 -0.062425  0.289548   \n",
       "2 -0.390790 -0.929125 -2.371427 -1.126142 -0.232861 -0.555668  0.060788   \n",
       "3 -0.256993 -0.627401 -0.376660 -0.145329 -0.640091 -0.257066 -0.007209   \n",
       "4  0.778642 -0.788620  0.440488  0.910248  0.421461  0.251527  0.307918   \n",
       "\n",
       "        7         8         9    ...       190       191       192       193  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.457742  0.640200 -0.876724  ... -0.426017 -1.258112 -0.547281 -0.609702   \n",
       "2 -2.067189  0.708972  1.869089  ...  1.769296  0.607791  1.685267  0.462870   \n",
       "3  0.066371 -0.923578  0.741953  ...  0.378577 -0.465361  0.712872 -0.108740   \n",
       "4 -0.429128 -0.015830  2.231030  ... -0.868681  0.239313  0.347212 -0.594535   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1 -0.957129  0.066992  1.802548 -0.343936  0.228859  0.889228  \n",
       "2  1.235561  2.705509 -3.699732  0.136413  1.322007  0.485764  \n",
       "3  0.223569  0.042677 -1.303379 -0.874297  0.215704 -0.256057  \n",
       "4  0.660311  0.547517 -0.272696 -0.192027 -0.037123 -1.403011  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embedding = pd.DataFrame(data.wordEmbedding)\n",
    "word_embedding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding.to_csv(\"../output/word_embedding.csv\", index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (8000, 1500)\n",
      "train label shape: (8000, 1)\n",
      "eval data shape: (2001, 1500)\n"
     ]
    }
   ],
   "source": [
    "print(\"train data shape: {}\".format(data.trainReviews.shape))\n",
    "print(\"train label shape: {}\".format(data.trainLabels.shape))\n",
    "print(\"eval data shape: {}\".format(data.evalReviews.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newsId</th>\n",
       "      <th>content</th>\n",
       "      <th>entity</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4e36d02a</td>\n",
       "      <td>无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型...</td>\n",
       "      <td>3d</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4e36d02a</td>\n",
       "      <td>无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型...</td>\n",
       "      <td>3d</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e36d02a</td>\n",
       "      <td>无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型...</td>\n",
       "      <td>3d</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4e36d02a</td>\n",
       "      <td>无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型...</td>\n",
       "      <td>3d</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4e36d02a</td>\n",
       "      <td>无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型...</td>\n",
       "      <td>3d</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     newsId                                            content entity emotion\n",
       "0  4e36d02a  无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型...     3d    None\n",
       "1  4e36d02a  无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型...     3d    None\n",
       "2  4e36d02a  无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型...     3d    None\n",
       "3  4e36d02a  无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型...     3d    None\n",
       "4  4e36d02a  无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型...     3d    None"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIndex = 8000\n",
    "\n",
    "# trainReviews = np.asarray(reviews[:trainIndex], dtype=\"int64\")\n",
    "trainLabels = np.array(labels[:trainIndex], dtype=\"float32\")\n",
    "\n",
    "# evalReviews = np.asarray(reviews[trainIndex:], dtype=\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainLabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.trainReviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.trainLabels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  1.0\n",
       "1  1.0\n",
       "2  1.0\n",
       "3  1.0\n",
       "4  1.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainLabels = pd.DataFrame(trainLabels)\n",
    "trainLabels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., ..., -1., -1., -1.], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalLabels = np.array(labels[trainIndex:], dtype=\"float32\")\n",
    "evalLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalLabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  1.0\n",
       "1  1.0\n",
       "2  1.0\n",
       "3  1.0\n",
       "4  1.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalLabels = pd.DataFrame(evalLabels)\n",
    "evalLabels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalLabels.to_csv(\"../output/eval_labels.csv\", index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLabels.to_csv(\"../output/train_labels.csv\", index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1490</th>\n",
       "      <th>1491</th>\n",
       "      <th>1492</th>\n",
       "      <th>1493</th>\n",
       "      <th>1494</th>\n",
       "      <th>1495</th>\n",
       "      <th>1496</th>\n",
       "      <th>1497</th>\n",
       "      <th>1498</th>\n",
       "      <th>1499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3973</td>\n",
       "      <td>964</td>\n",
       "      <td>13388</td>\n",
       "      <td>1560</td>\n",
       "      <td>223</td>\n",
       "      <td>964</td>\n",
       "      <td>8171</td>\n",
       "      <td>517</td>\n",
       "      <td>3262</td>\n",
       "      <td>223</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3973</td>\n",
       "      <td>964</td>\n",
       "      <td>13388</td>\n",
       "      <td>1560</td>\n",
       "      <td>223</td>\n",
       "      <td>964</td>\n",
       "      <td>8171</td>\n",
       "      <td>517</td>\n",
       "      <td>3262</td>\n",
       "      <td>223</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3973</td>\n",
       "      <td>964</td>\n",
       "      <td>13388</td>\n",
       "      <td>1560</td>\n",
       "      <td>223</td>\n",
       "      <td>964</td>\n",
       "      <td>8171</td>\n",
       "      <td>517</td>\n",
       "      <td>3262</td>\n",
       "      <td>223</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3973</td>\n",
       "      <td>964</td>\n",
       "      <td>13388</td>\n",
       "      <td>1560</td>\n",
       "      <td>223</td>\n",
       "      <td>964</td>\n",
       "      <td>8171</td>\n",
       "      <td>517</td>\n",
       "      <td>3262</td>\n",
       "      <td>223</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3973</td>\n",
       "      <td>964</td>\n",
       "      <td>13388</td>\n",
       "      <td>1560</td>\n",
       "      <td>223</td>\n",
       "      <td>964</td>\n",
       "      <td>8171</td>\n",
       "      <td>517</td>\n",
       "      <td>3262</td>\n",
       "      <td>223</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1      2     3     4     5     6     7     8     9     ...  1490  \\\n",
       "0  3973   964  13388  1560   223   964  8171   517  3262   223  ...     0   \n",
       "1  3973   964  13388  1560   223   964  8171   517  3262   223  ...     0   \n",
       "2  3973   964  13388  1560   223   964  8171   517  3262   223  ...     0   \n",
       "3  3973   964  13388  1560   223   964  8171   517  3262   223  ...     0   \n",
       "4  3973   964  13388  1560   223   964  8171   517  3262   223  ...     0   \n",
       "\n",
       "   1491  1492  1493  1494  1495  1496  1497  1498  1499  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 1500 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalReviews = pd.DataFrame(data.evalReviews)\n",
    "evalReviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalReviews.to_csv(\"../output/eval_num.csv\", index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1490</th>\n",
       "      <th>1491</th>\n",
       "      <th>1492</th>\n",
       "      <th>1493</th>\n",
       "      <th>1494</th>\n",
       "      <th>1495</th>\n",
       "      <th>1496</th>\n",
       "      <th>1497</th>\n",
       "      <th>1498</th>\n",
       "      <th>1499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>413</td>\n",
       "      <td>337</td>\n",
       "      <td>738</td>\n",
       "      <td>14100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>879</td>\n",
       "      <td>3779</td>\n",
       "      <td>151</td>\n",
       "      <td>549</td>\n",
       "      <td>336</td>\n",
       "      <td>865</td>\n",
       "      <td>1447</td>\n",
       "      <td>185</td>\n",
       "      <td>73</td>\n",
       "      <td>225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>879</td>\n",
       "      <td>3779</td>\n",
       "      <td>151</td>\n",
       "      <td>549</td>\n",
       "      <td>336</td>\n",
       "      <td>865</td>\n",
       "      <td>1447</td>\n",
       "      <td>185</td>\n",
       "      <td>73</td>\n",
       "      <td>225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>879</td>\n",
       "      <td>3779</td>\n",
       "      <td>151</td>\n",
       "      <td>549</td>\n",
       "      <td>336</td>\n",
       "      <td>865</td>\n",
       "      <td>1447</td>\n",
       "      <td>185</td>\n",
       "      <td>73</td>\n",
       "      <td>225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>879</td>\n",
       "      <td>3779</td>\n",
       "      <td>151</td>\n",
       "      <td>549</td>\n",
       "      <td>336</td>\n",
       "      <td>865</td>\n",
       "      <td>1447</td>\n",
       "      <td>185</td>\n",
       "      <td>73</td>\n",
       "      <td>225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2      3     4     5     6     7     8     9     ...  1490  \\\n",
       "0   413   337   738  14100     0     0     0     0     0     0  ...     0   \n",
       "1   879  3779   151    549   336   865  1447   185    73   225  ...     0   \n",
       "2   879  3779   151    549   336   865  1447   185    73   225  ...     0   \n",
       "3   879  3779   151    549   336   865  1447   185    73   225  ...     0   \n",
       "4   879  3779   151    549   336   865  1447   185    73   225  ...     0   \n",
       "\n",
       "   1491  1492  1493  1494  1495  1496  1497  1498  1499  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 1500 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainReviews = pd.DataFrame(data.trainReviews)\n",
    "trainReviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1490</th>\n",
       "      <th>1491</th>\n",
       "      <th>1492</th>\n",
       "      <th>1493</th>\n",
       "      <th>1494</th>\n",
       "      <th>1495</th>\n",
       "      <th>1496</th>\n",
       "      <th>1497</th>\n",
       "      <th>1498</th>\n",
       "      <th>1499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>3097</td>\n",
       "      <td>7527</td>\n",
       "      <td>7932</td>\n",
       "      <td>16088</td>\n",
       "      <td>64</td>\n",
       "      <td>1915</td>\n",
       "      <td>18026</td>\n",
       "      <td>278</td>\n",
       "      <td>3097</td>\n",
       "      <td>7527</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>3973</td>\n",
       "      <td>964</td>\n",
       "      <td>13388</td>\n",
       "      <td>1560</td>\n",
       "      <td>223</td>\n",
       "      <td>964</td>\n",
       "      <td>8171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>3973</td>\n",
       "      <td>964</td>\n",
       "      <td>13388</td>\n",
       "      <td>1560</td>\n",
       "      <td>223</td>\n",
       "      <td>964</td>\n",
       "      <td>8171</td>\n",
       "      <td>517</td>\n",
       "      <td>3262</td>\n",
       "      <td>223</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>3973</td>\n",
       "      <td>964</td>\n",
       "      <td>13388</td>\n",
       "      <td>1560</td>\n",
       "      <td>223</td>\n",
       "      <td>964</td>\n",
       "      <td>8171</td>\n",
       "      <td>517</td>\n",
       "      <td>3262</td>\n",
       "      <td>223</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>3973</td>\n",
       "      <td>964</td>\n",
       "      <td>13388</td>\n",
       "      <td>1560</td>\n",
       "      <td>223</td>\n",
       "      <td>964</td>\n",
       "      <td>8171</td>\n",
       "      <td>517</td>\n",
       "      <td>3262</td>\n",
       "      <td>223</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1      2      3    4     5      6    7     8     9  ...  1490  \\\n",
       "7995  3097  7527   7932  16088   64  1915  18026  278  3097  7527  ...     0   \n",
       "7996  3973   964  13388   1560  223   964   8171    0     0     0  ...     0   \n",
       "7997  3973   964  13388   1560  223   964   8171  517  3262   223  ...     0   \n",
       "7998  3973   964  13388   1560  223   964   8171  517  3262   223  ...     0   \n",
       "7999  3973   964  13388   1560  223   964   8171  517  3262   223  ...     0   \n",
       "\n",
       "      1491  1492  1493  1494  1495  1496  1497  1498  1499  \n",
       "7995     0     0     0     0     0     0     0     0     0  \n",
       "7996     0     0     0     0     0     0     0     0     0  \n",
       "7997     0     0     0     0     0     0     0     0     0  \n",
       "7998     0     0     0     0     0     0     0     0     0  \n",
       "7999     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 1500 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../output/train_num.csv\", sep='\\t')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.asarray(df)\n",
    "len(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainReviews.to_csv(\"../output/train_num.csv\", index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型升级和跨越发展！誉洋3d机器视觉引发展会参观热潮在大连誉洋工业智能的展位，机器人自动抓取物件让人眼前一亮',\n",
       " '无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型升级和跨越发展！誉洋3d机器视觉引发展会参观热潮在大连誉洋工业智能的展位，机器人自动抓取物件让人眼前一亮。机器人在3d视觉的引导下精准定位杂乱无序的目标，并实现准确快速抓取，整个过程井然有序，无需任何人工干预',\n",
       " '无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型升级和跨越发展！誉洋3d机器视觉引发展会参观热潮在大连誉洋工业智能的展位，机器人自动抓取物件让人眼前一亮。机器人在3d视觉的引导下精准定位杂乱无序的目标，并实现准确快速抓取，整个过程井然有序，无需任何人工干预。誉洋现场工程师介绍，制造企业采用誉洋kineye®3d机器视觉系统，以往繁琐、枯燥的物料搬运工作交给了机器人，这样不但解放了人力，还提升了物流效率',\n",
       " '无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型升级和跨越发展！誉洋3d机器视觉引发展会参观热潮在大连誉洋工业智能的展位，机器人自动抓取物件让人眼前一亮。机器人在3d视觉的引导下精准定位杂乱无序的目标，并实现准确快速抓取，整个过程井然有序，无需任何人工干预。誉洋现场工程师介绍，制造企业采用誉洋kineye®3d机器视觉系统，以往繁琐、枯燥的物料搬运工作交给了机器人，这样不但解放了人力，还提升了物流效率。这套3d机器视觉已在国内多家知名企业成功实施应用，得到了一致认可与好评',\n",
       " '无论是展会规模、展示范围以及专业观众的人数，都实现了快速的增长，极大地推动了我国制造业的转型升级和跨越发展！誉洋3d机器视觉引发展会参观热潮在大连誉洋工业智能的展位，机器人自动抓取物件让人眼前一亮。机器人在3d视觉的引导下精准定位杂乱无序的目标，并实现准确快速抓取，整个过程井然有序，无需任何人工干预。誉洋现场工程师介绍，制造企业采用誉洋kineye®3d机器视觉系统，以往繁琐、枯燥的物料搬运工作交给了机器人，这样不但解放了人力，还提升了物流效率。这套3d机器视觉已在国内多家知名企业成功实施应用，得到了一致认可与好评。kineye®3d机器视觉实现企业智能制造誉洋工业智能有限公司自成立以来，一直专注于工业智能设备的研发、生产制造和服务，创新理念伴随企业不断成长']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = df_test[\"content\"].tolist()\n",
    "content[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[\"emotion\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "files = os.listdir('../字典')\n",
    "for file_name in files:\n",
    "    jieba.load_userdict('../字典/' + file_name)\n",
    "jieba.load_userdict('../runs/entity.txt')\n",
    "\n",
    "stop_words = []\n",
    "with open('../data/stop_words.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.replace(\"\\n\", \"\")\n",
    "        stop_words.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  data finish\n",
      "500  data finish\n",
      "1000  data finish\n",
      "1500  data finish\n",
      "2000  data finish\n",
      "2500  data finish\n",
      "3000  data finish\n",
      "3500  data finish\n",
      "4000  data finish\n",
      "4500  data finish\n",
      "5000  data finish\n",
      "5500  data finish\n",
      "6000  data finish\n",
      "6500  data finish\n",
      "7000  data finish\n",
      "7500  data finish\n",
      "8000  data finish\n",
      "8500  data finish\n",
      "9000  data finish\n",
      "9500  data finish\n"
     ]
    }
   ],
   "source": [
    "all_docs = []\n",
    "i = 0\n",
    "for data in content:\n",
    "    words = jieba.cut(data)\n",
    "    words = filter(lambda x: x not in stop_words, words)\n",
    "    all_docs.append(list(words))\n",
    "    if i % 500 == 0:\n",
    "        print(i, ' data finish')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1420331"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allWords = [word for doc in all_docs for word in doc]\n",
    "len(allWords)  # 573w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24802"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCount = Counter(allWords)  # 统计词频\n",
    "len(wordCount) # 16w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('年', 12783),\n",
       "  ('微信', 11677),\n",
       "  ('中', 9189),\n",
       "  ('市场', 6875),\n",
       "  ('月', 5972),\n",
       "  ('发展', 5609),\n",
       "  ('产品', 5169),\n",
       "  ('腾讯', 4979),\n",
       "  ('20', 4181),\n",
       "  ('企业', 4165)],\n",
       " 24802)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortWordCount = sorted(wordCount.items(), key=lambda x: x[1], reverse=True)\n",
    "sortWordCount[0:10], len(sortWordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23518"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 去除低频词\n",
    "words = [item[0] for item in sortWordCount if item[1] >= 2]\n",
    "len(words) # 3w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['年', '微信', '中', '市场', '月', '发展', '产品', '腾讯', '20', '企业']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"content\"] = all_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newsId</th>\n",
       "      <th>content</th>\n",
       "      <th>entity</th>\n",
       "      <th>emotion</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4e36d02a</td>\n",
       "      <td>[无论是, 展会, 规模, 展示, 专业, 观众, 人数, 快速, 增长, 推动, 我国, ...</td>\n",
       "      <td>3d</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4e36d02a</td>\n",
       "      <td>[无论是, 展会, 规模, 展示, 专业, 观众, 人数, 快速, 增长, 推动, 我国, ...</td>\n",
       "      <td>3d</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e36d02a</td>\n",
       "      <td>[无论是, 展会, 规模, 展示, 专业, 观众, 人数, 快速, 增长, 推动, 我国, ...</td>\n",
       "      <td>3d</td>\n",
       "      <td>1</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4e36d02a</td>\n",
       "      <td>[无论是, 展会, 规模, 展示, 专业, 观众, 人数, 快速, 增长, 推动, 我国, ...</td>\n",
       "      <td>3d</td>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4e36d02a</td>\n",
       "      <td>[无论是, 展会, 规模, 展示, 专业, 观众, 人数, 快速, 增长, 推动, 我国, ...</td>\n",
       "      <td>3d</td>\n",
       "      <td>1</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     newsId                                            content entity  \\\n",
       "0  4e36d02a  [无论是, 展会, 规模, 展示, 专业, 观众, 人数, 快速, 增长, 推动, 我国, ...     3d   \n",
       "1  4e36d02a  [无论是, 展会, 规模, 展示, 专业, 观众, 人数, 快速, 增长, 推动, 我国, ...     3d   \n",
       "2  4e36d02a  [无论是, 展会, 规模, 展示, 专业, 观众, 人数, 快速, 增长, 推动, 我国, ...     3d   \n",
       "3  4e36d02a  [无论是, 展会, 规模, 展示, 专业, 观众, 人数, 快速, 增长, 推动, 我国, ...     3d   \n",
       "4  4e36d02a  [无论是, 展会, 规模, 展示, 专业, 观众, 人数, 快速, 增长, 推动, 我国, ...     3d   \n",
       "\n",
       "   emotion  len  \n",
       "0        1   98  \n",
       "1        1  150  \n",
       "2        1  224  \n",
       "3        1  260  \n",
       "4        1  333  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _getWordEmbedding(words, embeddingSize=200):\n",
    "    \"\"\"\n",
    "    按照我们的数据集中的单词取出预训练好的word2vec中的词向量\n",
    "    \"\"\"\n",
    "    from gensim.models import FastText\n",
    "    wordVec = FastText.load('../runs/fasttext_model')\n",
    "    vocab = []\n",
    "    wordEmbedding = []\n",
    "\n",
    "    # 添加 \"pad\" 和 \"UNK\", \n",
    "    vocab.append(\"pad\")\n",
    "    vocab.append(\"UNK\")\n",
    "    wordEmbedding.append(np.zeros(embeddingSize))\n",
    "    wordEmbedding.append(np.random.randn(embeddingSize))\n",
    "\n",
    "    for word in words:\n",
    "        try:\n",
    "            vector = wordVec.wv[word] # 每个词200维\n",
    "            vocab.append(word)  # 词表\n",
    "            wordEmbedding.append(vector) # 词向量\n",
    "        except:\n",
    "            print(word + \"不存在于词向量中\")\n",
    "\n",
    "    return vocab, np.array(wordEmbedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "看完不存在于词向量中\n",
      "应属不存在于词向量中\n",
      "改出不存在于词向量中\n",
      "较快不存在于词向量中\n",
      "后端不存在于词向量中\n",
      "赶去不存在于词向量中\n",
      "理出不存在于词向量中\n",
      "之举不存在于词向量中\n",
      "听清不存在于词向量中\n",
      "自股不存在于词向量中\n",
      "熟到不存在于词向量中\n",
      "体用不存在于词向量中\n",
      "中韩不存在于词向量中\n",
      "党心不存在于词向量中\n",
      "其钱不存在于词向量中\n",
      "小场不存在于词向量中\n",
      "亚都不存在于词向量中\n",
      "首月不存在于词向量中\n",
      "想靠不存在于词向量中\n",
      "听完不存在于词向量中\n",
      "所讲不存在于词向量中\n",
      "收得不存在于词向量中\n",
      "vh不存在于词向量中\n",
      "一划不存在于词向量中\n",
      "做分不存在于词向量中\n",
      "抢得不存在于词向量中\n",
      "拍去不存在于词向量中\n",
      "没数不存在于词向量中\n"
     ]
    }
   ],
   "source": [
    "vocab, wordEmbedding = _getWordEmbedding(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23492, 23492)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab),len(wordEmbedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordEmbedding[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordToIndex = dict(zip(vocab, list(range(len(vocab)))))\n",
    "indexToWord = dict(zip(list(range(len(vocab))), vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pad': 0,\n",
       " 'UNK': 1,\n",
       " '年': 2,\n",
       " '微信': 3,\n",
       " '中': 4,\n",
       " '市场': 5,\n",
       " '月': 6,\n",
       " '发展': 7,\n",
       " '产品': 8,\n",
       " '腾讯': 9,\n",
       " '20': 10,\n",
       " '企业': 11,\n",
       " '公司': 12,\n",
       " '美国': 13,\n",
       " '日': 14,\n",
       " '券商': 15,\n",
       " '新': 16,\n",
       " '减值': 17,\n",
       " '用户': 18,\n",
       " '业务': 19,\n",
       " '中国': 20,\n",
       " '我国': 21,\n",
       " '2018': 22,\n",
       " '时': 23,\n",
       " '国债期货': 24,\n",
       " '数据': 25,\n",
       " 'ar': 26,\n",
       " '行业': 27,\n",
       " '占': 28,\n",
       " '平台': 29,\n",
       " '技术': 30,\n",
       " '投资': 31,\n",
       " '农业': 32,\n",
       " '信托': 33,\n",
       " '切削': 34,\n",
       " '15': 35,\n",
       " '包括': 36,\n",
       " '做': 37,\n",
       " '2019': 38,\n",
       " '服务': 39,\n",
       " '说': 40,\n",
       " '影响': 41,\n",
       " '牛市': 42,\n",
       " '高': 43,\n",
       " '投资者': 44,\n",
       " '提供': 45,\n",
       " '模式': 46,\n",
       " '独角兽': 47,\n",
       " '券商股': 48,\n",
       " '实验室': 49,\n",
       " '全球': 50,\n",
       " '17': 51,\n",
       " '国债': 52,\n",
       " '建设': 53,\n",
       " '前': 54,\n",
       " '华为': 55,\n",
       " '工业': 56,\n",
       " '融资': 57,\n",
       " '资产': 58,\n",
       " '方式': 59,\n",
       " '10': 60,\n",
       " '刀具': 61,\n",
       " '生态': 62,\n",
       " '领域': 63,\n",
       " '品牌': 64,\n",
       " ' ': 65,\n",
       " '机构': 66,\n",
       " 'shell': 67,\n",
       " '女性': 68,\n",
       " '支持': 69,\n",
       " '生产': 70,\n",
       " '互联网': 71,\n",
       " '参与': 72,\n",
       " '增长': 73,\n",
       " '金融': 74,\n",
       " '快手': 75,\n",
       " '发布': 76,\n",
       " '变化': 77,\n",
       " '提升': 78,\n",
       " '工作': 79,\n",
       " '情况': 80,\n",
       " '风险': 81,\n",
       " '项目': 82,\n",
       " '网络': 83,\n",
       " '持续': 84,\n",
       " '收益': 85,\n",
       " '农民工': 86,\n",
       " '时间': 87,\n",
       " '25': 88,\n",
       " '功能': 89,\n",
       " '12': 90,\n",
       " '循环': 91,\n",
       " '能力': 92,\n",
       " '团队': 93,\n",
       " '需求': 94,\n",
       " '过程': 95,\n",
       " '13': 96,\n",
       " '显示': 97,\n",
       " '基金': 98,\n",
       " '信息': 99,\n",
       " '资金': 100,\n",
       " '带来': 101,\n",
       " '褚时健': 102,\n",
       " '损失': 103,\n",
       " 'qq': 104,\n",
       " '未来': 105,\n",
       " '一种': 106,\n",
       " '选择': 107,\n",
       " '内容': 108,\n",
       " '上市': 109,\n",
       " '系统': 110,\n",
       " '增加': 111,\n",
       " '体系': 112,\n",
       " '收入': 113,\n",
       " '国家': 114,\n",
       " '发行': 115,\n",
       " '分析': 116,\n",
       " '类': 117,\n",
       " '家': 118,\n",
       " '行情': 119,\n",
       " '5g': 120,\n",
       " '全国': 121,\n",
       " '内部': 122,\n",
       " '金融资产': 123,\n",
       " '国内': 124,\n",
       " '入口': 125,\n",
       " '准则': 126,\n",
       " '合作': 127,\n",
       " '德国': 128,\n",
       " 'r': 129,\n",
       " '机会': 130,\n",
       " '超过': 131,\n",
       " '压力': 132,\n",
       " '交易': 133,\n",
       " '相关': 134,\n",
       " '资源': 135,\n",
       " '里': 136,\n",
       " '超': 137,\n",
       " '人类': 138,\n",
       " '式': 139,\n",
       " '推出': 140,\n",
       " '销售': 141,\n",
       " '关系': 142,\n",
       " '报告': 143,\n",
       " '价格': 144,\n",
       " '社交': 145,\n",
       " '低': 146,\n",
       " '银行': 147,\n",
       " '张小龙': 148,\n",
       " '空间': 149,\n",
       " '利用': 150,\n",
       " '成本': 151,\n",
       " '规模': 152,\n",
       " '环境': 153,\n",
       " '提出': 154,\n",
       " '生活': 155,\n",
       " '核心': 156,\n",
       " '电影': 157,\n",
       " 'h': 158,\n",
       " '政策': 159,\n",
       " '设备': 160,\n",
       " '优势': 161,\n",
       " '方案': 162,\n",
       " '质押': 163,\n",
       " '30': 164,\n",
       " '相比': 165,\n",
       " '城市': 166,\n",
       " '结构': 167,\n",
       " '预期': 168,\n",
       " '流量': 169,\n",
       " '消息': 170,\n",
       " '上涨': 171,\n",
       " '原因': 172,\n",
       " '员工': 173,\n",
       " '战略': 174,\n",
       " '社会': 175,\n",
       " '采用': 176,\n",
       " 'a': 177,\n",
       " '估值': 178,\n",
       " '直播': 179,\n",
       " '经济': 180,\n",
       " '比例': 181,\n",
       " '大幅': 182,\n",
       " '传统': 183,\n",
       " '数量': 184,\n",
       " '快速': 185,\n",
       " '亿': 186,\n",
       " '宅基地': 187,\n",
       " '飞机': 188,\n",
       " '走': 189,\n",
       " '创新': 190,\n",
       " '融合': 191,\n",
       " '关注': 192,\n",
       " '正式': 193,\n",
       " '存量': 194,\n",
       " '万': 195,\n",
       " '股票': 196,\n",
       " '消费者': 197,\n",
       " '职业': 198,\n",
       " '表现': 199,\n",
       " '开启': 200,\n",
       " 'ar眼镜': 201,\n",
       " '平均': 202,\n",
       " '小贷': 203,\n",
       " '2014': 204,\n",
       " '信托公司': 205,\n",
       " '产业': 206,\n",
       " '经营': 207,\n",
       " '网易': 208,\n",
       " '约': 209,\n",
       " '设计': 210,\n",
       " '材料': 211,\n",
       " '计算': 212,\n",
       " '印度': 213,\n",
       " '成功': 214,\n",
       " '形式': 215,\n",
       " 'it': 216,\n",
       " '提高': 217,\n",
       " '金刚石': 218,\n",
       " '人工智能': 219,\n",
       " '部门': 220,\n",
       " '吨': 221,\n",
       " '游戏': 222,\n",
       " '事业': 223,\n",
       " '推动': 224,\n",
       " '标准': 225,\n",
       " '买入': 226,\n",
       " '管理': 227,\n",
       " '预计': 228,\n",
       " '因素': 229,\n",
       " '抖音': 230,\n",
       " 'maxta': 231,\n",
       " '消费': 232,\n",
       " '称': 233,\n",
       " '水平': 234,\n",
       " '希望': 235,\n",
       " '视频': 236,\n",
       " '购买': 237,\n",
       " '研究': 238,\n",
       " '客户': 239,\n",
       " '月饼': 240,\n",
       " 'st': 241,\n",
       " '推广': 242,\n",
       " '收购': 243,\n",
       " '机器人': 244,\n",
       " '整体': 245,\n",
       " '股权': 246,\n",
       " '手机': 247,\n",
       " '岁': 248,\n",
       " '计提': 249,\n",
       " '时代': 250,\n",
       " '场景': 251,\n",
       " '实施': 252,\n",
       " '更好': 253,\n",
       " '去年': 254,\n",
       " '料': 255,\n",
       " '筹码': 256,\n",
       " '发生': 257,\n",
       " '端': 258,\n",
       " '级': 259,\n",
       " '网站': 260,\n",
       " '成立': 261,\n",
       " '阶段': 262,\n",
       " '国际': 263,\n",
       " '条件': 264,\n",
       " '返售': 265,\n",
       " '累计': 266,\n",
       " '年期': 267,\n",
       " '贷款': 268,\n",
       " '期限': 269,\n",
       " '物流地产': 270,\n",
       " '价值': 271,\n",
       " '来伊份': 272,\n",
       " '特别': 273,\n",
       " '成熟': 274,\n",
       " '\\u200b': 275,\n",
       " '低于': 276,\n",
       " '操作': 277,\n",
       " '房地产企业': 278,\n",
       " '越来越': 279,\n",
       " '股价': 280,\n",
       " '刃口': 281,\n",
       " '体验': 282,\n",
       " '软件': 283,\n",
       " '拥有': 284,\n",
       " '运行': 285,\n",
       " '上线': 286,\n",
       " '规划': 287,\n",
       " '未': 288,\n",
       " '建议': 289,\n",
       " '厚度': 290,\n",
       " '资本': 291,\n",
       " '较大': 292,\n",
       " '品种': 293,\n",
       " '边缘计算': 294,\n",
       " '稻谷': 295,\n",
       " '刘继恩': 296,\n",
       " '广告': 297,\n",
       " '科技': 298,\n",
       " '执行': 299,\n",
       " '负责': 300,\n",
       " 'b': 301,\n",
       " 'google': 302,\n",
       " '奖金': 303,\n",
       " '优化': 304,\n",
       " '发现': 305,\n",
       " '一位': 306,\n",
       " '建立': 307,\n",
       " '下降': 308,\n",
       " '减少': 309,\n",
       " '两个': 310,\n",
       " '秋香': 311,\n",
       " '代表': 312,\n",
       " '特征': 313,\n",
       " '信用': 314,\n",
       " '大数据': 315,\n",
       " '化': 316,\n",
       " '想': 317,\n",
       " '申请': 318,\n",
       " '作用': 319,\n",
       " '微细': 320,\n",
       " '业绩': 321,\n",
       " '开支': 322,\n",
       " '2016': 323,\n",
       " '状态': 324,\n",
       " '增速': 325,\n",
       " '推进': 326,\n",
       " '支付': 327,\n",
       " '比重': 328,\n",
       " '微信支付': 329,\n",
       " '网友': 330,\n",
       " '中产': 331,\n",
       " '独立': 332,\n",
       " '美国国债': 333,\n",
       " '资产负债表': 334,\n",
       " '之间': 335,\n",
       " '专业': 336,\n",
       " '突破': 337,\n",
       " '地区': 338,\n",
       " '境外': 339,\n",
       " '商业': 340,\n",
       " '龙头': 341,\n",
       " '活动': 342,\n",
       " '当年': 343,\n",
       " '监管': 344,\n",
       " '深度': 345,\n",
       " '开放': 346,\n",
       " '群': 347,\n",
       " '稳定': 348,\n",
       " '进一步': 349,\n",
       " '开发': 350,\n",
       " '智能': 351,\n",
       " '记者': 352,\n",
       " '可视化': 353,\n",
       " '发挥': 354,\n",
       " '期间': 355,\n",
       " '盈利': 356,\n",
       " '计划': 357,\n",
       " '一级': 358,\n",
       " '农户': 359,\n",
       " '综合': 360,\n",
       " '科创板': 361,\n",
       " '香港': 362,\n",
       " '介绍': 363,\n",
       " '华云数据': 364,\n",
       " '号': 365,\n",
       " '持有': 366,\n",
       " '研发': 367,\n",
       " '文化': 368,\n",
       " 'on': 369,\n",
       " '新生': 370,\n",
       " '50': 371,\n",
       " '媒体': 372,\n",
       " '支撑': 373,\n",
       " '第一': 374,\n",
       " '区域': 375,\n",
       " '巴基斯坦': 376,\n",
       " '现货': 377,\n",
       " '成交': 378,\n",
       " '降价': 379,\n",
       " '算法': 380,\n",
       " '布局': 381,\n",
       " '企业家': 382,\n",
       " '位置': 383,\n",
       " '半径': 384,\n",
       " '方法': 385,\n",
       " '基础': 386,\n",
       " '比特币': 387,\n",
       " '万桶': 388,\n",
       " '这是': 389,\n",
       " '期': 390,\n",
       " '切削力': 391,\n",
       " '指数': 392,\n",
       " '政府': 393,\n",
       " '资本市场': 394,\n",
       " '调整': 395,\n",
       " '意义': 396,\n",
       " '计入': 397,\n",
       " '厂商': 398,\n",
       " '美国政府': 399,\n",
       " '分享': 400,\n",
       " '报道': 401,\n",
       " '人员': 402,\n",
       " 'ss': 403,\n",
       " '营销': 404,\n",
       " '配置': 405,\n",
       " '型': 406,\n",
       " '改善': 407,\n",
       " '李嘉诚': 408,\n",
       " '费用': 409,\n",
       " '解决': 410,\n",
       " '挑战': 411,\n",
       " '成交量': 412,\n",
       " '趋势': 413,\n",
       " '余额': 414,\n",
       " 'c': 415,\n",
       " '一年': 416,\n",
       " '处于': 417,\n",
       " '下滑': 418,\n",
       " '适合': 419,\n",
       " '物流': 420,\n",
       " '变动': 421,\n",
       " '分为': 422,\n",
       " '最小': 423,\n",
       " '面临': 424,\n",
       " '近日': 425,\n",
       " '依然': 426,\n",
       " '小程序': 427,\n",
       " '指': 428,\n",
       " '模型': 429,\n",
       " '外': 430,\n",
       " '环节': 431,\n",
       " '真实': 432,\n",
       " '上海': 433,\n",
       " '运营': 434,\n",
       " '商品': 435,\n",
       " '磨损': 436,\n",
       " '现货市场': 437,\n",
       " '线': 438,\n",
       " '权益': 439,\n",
       " '首次': 440,\n",
       " '集团': 441,\n",
       " '走势': 442,\n",
       " '涨幅': 443,\n",
       " '成': 444,\n",
       " '厚': 445,\n",
       " '具备': 446,\n",
       " '方向': 447,\n",
       " '科目': 448,\n",
       " '详情': 449,\n",
       " '能源': 450,\n",
       " '自媒体': 451,\n",
       " '用于': 452,\n",
       " 'n': 453,\n",
       " '指出': 454,\n",
       " '60': 455,\n",
       " '效果': 456,\n",
       " '房地产信托': 457,\n",
       " '个股': 458,\n",
       " '单位': 459,\n",
       " '第三方': 460,\n",
       " '竞争': 461,\n",
       " '打造': 462,\n",
       " '很大': 463,\n",
       " '下跌': 464,\n",
       " '保护': 465,\n",
       " '21': 466,\n",
       " '版本': 467,\n",
       " '开发商': 468,\n",
       " '修复': 469,\n",
       " '商业银行': 470,\n",
       " '启动': 471,\n",
       " '基础设施': 472,\n",
       " '计量': 473,\n",
       " '匹配': 474,\n",
       " '家庭': 475,\n",
       " '程度': 476,\n",
       " '总': 477,\n",
       " '加快': 478,\n",
       " '一轮': 479,\n",
       " '汪峰': 480,\n",
       " '多年': 481,\n",
       " '连接': 482,\n",
       " '导致': 483,\n",
       " '关键词': 484,\n",
       " '板块': 485,\n",
       " '支付宝': 486,\n",
       " '讨论': 487,\n",
       " '目的': 488,\n",
       " '下调': 489,\n",
       " '废钢': 490,\n",
       " '资产质量': 491,\n",
       " '电商': 492,\n",
       " '中大': 493,\n",
       " '衍生': 494,\n",
       " '重点': 495,\n",
       " '简单': 496,\n",
       " '最终': 497,\n",
       " '度': 498,\n",
       " '远': 499,\n",
       " '喜欢': 500,\n",
       " '搜狗': 501,\n",
       " '站': 502,\n",
       " '减轻': 503,\n",
       " '通知': 504,\n",
       " '改变': 505,\n",
       " '旗下': 506,\n",
       " '乡村': 507,\n",
       " '升级': 508,\n",
       " '应': 509,\n",
       " '连续': 510,\n",
       " '内外': 511,\n",
       " '有人': 512,\n",
       " '工具': 513,\n",
       " '增值税': 514,\n",
       " 'gdp': 515,\n",
       " '积累': 516,\n",
       " '获取': 517,\n",
       " 'i': 518,\n",
       " '一款': 519,\n",
       " 'ai': 520,\n",
       " '组织': 521,\n",
       " '初步': 522,\n",
       " 'w': 523,\n",
       " '收到': 524,\n",
       " '优先级': 525,\n",
       " '两': 526,\n",
       " '深圳': 527,\n",
       " '体现': 528,\n",
       " '酸菜鱼': 529,\n",
       " '三个': 530,\n",
       " '量': 531,\n",
       " '质量': 532,\n",
       " '投入': 533,\n",
       " '逻辑': 534,\n",
       " '率先': 535,\n",
       " '人士': 536,\n",
       " '推荐': 537,\n",
       " '大部分': 538,\n",
       " '总部': 539,\n",
       " '特步': 540,\n",
       " '接受': 541,\n",
       " '年度': 542,\n",
       " '期货': 543,\n",
       " '公允价值': 544,\n",
       " '确认': 545,\n",
       " '崛起': 546,\n",
       " '人工智能名片': 547,\n",
       " '展示': 548,\n",
       " '登录': 549,\n",
       " '类型': 550,\n",
       " '初期': 551,\n",
       " '公开': 552,\n",
       " '越南': 553,\n",
       " '马化腾': 554,\n",
       " '精准': 555,\n",
       " '布匹': 556,\n",
       " '钢铁': 557,\n",
       " '扣除': 558,\n",
       " '纷纷': 559,\n",
       " '借助': 560,\n",
       " '拍卖': 561,\n",
       " '是因为': 562,\n",
       " '卖家': 563,\n",
       " '钢筋': 564,\n",
       " '直播行业': 565,\n",
       " '构建': 566,\n",
       " '符合': 567,\n",
       " '文件': 568,\n",
       " '英国': 569,\n",
       " '章子怡': 570,\n",
       " '设置': 571,\n",
       " '春节': 572,\n",
       " '11': 573,\n",
       " '工程': 574,\n",
       " '店铺': 575,\n",
       " '加工': 576,\n",
       " '部署': 577,\n",
       " '原油': 578,\n",
       " '最新': 579,\n",
       " '制作': 580,\n",
       " '云计算': 581,\n",
       " '一是': 582,\n",
       " '沟通': 583,\n",
       " '透露': 584,\n",
       " '高于': 585,\n",
       " '难以': 586,\n",
       " 's': 587,\n",
       " '遭受': 588,\n",
       " '门店': 589,\n",
       " '排放': 590,\n",
       " '目标': 591,\n",
       " '位于': 592,\n",
       " 'bash': 593,\n",
       " '20%': 594,\n",
       " '完善': 595,\n",
       " '有限': 596,\n",
       " '日均': 597,\n",
       " '事': 598,\n",
       " '更是': 599,\n",
       " '创始人': 600,\n",
       " 'f': 601,\n",
       " '类似': 602,\n",
       " '效率': 603,\n",
       " '涨': 604,\n",
       " '几个': 605,\n",
       " '制造业': 606,\n",
       " '硬件': 607,\n",
       " '水泥': 608,\n",
       " '制度': 609,\n",
       " '总量': 610,\n",
       " '商家': 611,\n",
       " '大型': 612,\n",
       " '地方': 613,\n",
       " '高端': 614,\n",
       " '建房': 615,\n",
       " '压块': 616,\n",
       " '债券市场': 617,\n",
       " '多个': 618,\n",
       " '真的': 619,\n",
       " '凯莉': 620,\n",
       " '意味着': 621,\n",
       " '迎来': 622,\n",
       " '北京': 623,\n",
       " '领英': 624,\n",
       " '点': 625,\n",
       " '短': 626,\n",
       " '光伏发电': 627,\n",
       " '面对': 628,\n",
       " '差距': 629,\n",
       " '引发': 630,\n",
       " '心理': 631,\n",
       " '90': 632,\n",
       " '房地产': 633,\n",
       " '天猫精灵cc': 634,\n",
       " '转让': 635,\n",
       " '力度': 636,\n",
       " '影响力': 637,\n",
       " '广阔': 638,\n",
       " '角度': 639,\n",
       " '事情': 640,\n",
       " '强': 641,\n",
       " '公民': 642,\n",
       " '经历': 643,\n",
       " '年终奖': 644,\n",
       " '态势': 645,\n",
       " '路面': 646,\n",
       " '切换': 647,\n",
       " '华东': 648,\n",
       " '自然': 649,\n",
       " '加大': 650,\n",
       " '现象': 651,\n",
       " '税费': 652,\n",
       " '世界': 653,\n",
       " '将会': 654,\n",
       " '架构': 655,\n",
       " '期货市场': 656,\n",
       " '起诉': 657,\n",
       " '个人信息': 658,\n",
       " '展开': 659,\n",
       " '一家': 660,\n",
       " '见图': 661,\n",
       " '中美': 662,\n",
       " 'osmo': 663,\n",
       " '分布': 664,\n",
       " '测试': 665,\n",
       " '开源': 666,\n",
       " '商业化': 667,\n",
       " '破碎': 668,\n",
       " '强势': 669,\n",
       " '债券': 670,\n",
       " '令': 671,\n",
       " '条码': 672,\n",
       " '之外': 673,\n",
       " '历史': 674,\n",
       " '商业模式': 675,\n",
       " '力量': 676,\n",
       " '探索': 677,\n",
       " '有助于': 678,\n",
       " '呈现': 679,\n",
       " '分配': 680,\n",
       " '永远': 681,\n",
       " '泡沫': 682,\n",
       " '千岛湖': 683,\n",
       " '高质量': 684,\n",
       " '回落': 685,\n",
       " '图': 686,\n",
       " '房子': 687,\n",
       " '圆弧': 688,\n",
       " '始终': 689,\n",
       " '本文': 690,\n",
       " '中远公司': 691,\n",
       " '周期': 692,\n",
       " '结束': 693,\n",
       " '能耗': 694,\n",
       " '退出': 695,\n",
       " '参考': 696,\n",
       " '二级': 697,\n",
       " '黄金': 698,\n",
       " '张嘉倪': 699,\n",
       " '风控': 700,\n",
       " '做出': 701,\n",
       " '工资': 702,\n",
       " '眼镜': 703,\n",
       " '链': 704,\n",
       " '仅为': 705,\n",
       " '中心': 706,\n",
       " '2000': 707,\n",
       " '印度标准局': 708,\n",
       " '需': 709,\n",
       " '规范': 710,\n",
       " 'pc': 711,\n",
       " '认证': 712,\n",
       " '肯定': 713,\n",
       " '近期': 714,\n",
       " '参与者': 715,\n",
       " '概念': 716,\n",
       " '跑': 717,\n",
       " '诞生': 718,\n",
       " '产量': 719,\n",
       " '收入额': 720,\n",
       " '人才': 721,\n",
       " '娱乐': 722,\n",
       " '特性': 723,\n",
       " 'pocket': 724,\n",
       " '系列': 725,\n",
       " '护照': 726,\n",
       " '工件': 727,\n",
       " '更高': 728,\n",
       " '利率': 729,\n",
       " '结论': 730,\n",
       " '高鑫零售': 731,\n",
       " '经验': 732,\n",
       " '系': 733,\n",
       " '80': 734,\n",
       " '官方': 735,\n",
       " 'e': 736,\n",
       " '通信': 737,\n",
       " '拿到': 738,\n",
       " 'te': 739,\n",
       " '降低': 740,\n",
       " '年轻': 741,\n",
       " '宁波海越': 742,\n",
       " '电源': 743,\n",
       " '粉丝': 744,\n",
       " '节目': 745,\n",
       " '并购': 746,\n",
       " '丹麦': 747,\n",
       " '余热': 748,\n",
       " '在内': 749,\n",
       " '各类': 750,\n",
       " '间': 751,\n",
       " '走向': 752,\n",
       " '定位': 753,\n",
       " '品类': 754,\n",
       " '案例': 755,\n",
       " '特斯拉': 756,\n",
       " '输入法': 757,\n",
       " '有限公司': 758,\n",
       " '第三': 759,\n",
       " '折叠': 760,\n",
       " '转型': 761,\n",
       " '注册': 762,\n",
       " '海外': 763,\n",
       " '总办': 764,\n",
       " '配置文件': 765,\n",
       " '买': 766,\n",
       " '芯片': 767,\n",
       " '渠道': 768,\n",
       " '波动': 769,\n",
       " '巨头': 770,\n",
       " '市场规模': 771,\n",
       " '机械': 772,\n",
       " '正': 773,\n",
       " '短期': 774,\n",
       " '主席': 775,\n",
       " '一部分': 776,\n",
       " '男性': 777,\n",
       " '315': 778,\n",
       " '买超': 779,\n",
       " '此前': 780,\n",
       " '摘要': 781,\n",
       " '认知': 782,\n",
       " '房企': 783,\n",
       " '回购': 784,\n",
       " '互动': 785,\n",
       " '落地': 786,\n",
       " '三英战': 787,\n",
       " '被绑': 788,\n",
       " '枷锁': 789,\n",
       " '收益权': 790,\n",
       " '注重': 791,\n",
       " '灵活': 792,\n",
       " '保障': 793,\n",
       " '唯品会': 794,\n",
       " '理解': 795,\n",
       " '受': 796,\n",
       " '国务院': 797,\n",
       " '区别': 798,\n",
       " 'app': 799,\n",
       " '使命': 800,\n",
       " '变现': 801,\n",
       " '华北': 802,\n",
       " '关键': 803,\n",
       " '安装': 804,\n",
       " '实行': 805,\n",
       " '本轮': 806,\n",
       " '裹挟': 807,\n",
       " '两个世界': 808,\n",
       " '来源': 809,\n",
       " '这一': 810,\n",
       " '搜': 811,\n",
       " '增大': 812,\n",
       " '京东': 813,\n",
       " '三季度': 814,\n",
       " '水': 815,\n",
       " '百度': 816,\n",
       " '金额': 817,\n",
       " '易商红木': 818,\n",
       " '大润发': 819,\n",
       " '猎头': 820,\n",
       " '领导': 821,\n",
       " '高度': 822,\n",
       " '老公': 823,\n",
       " '控制': 824,\n",
       " '合同': 825,\n",
       " '拍摄': 826,\n",
       " '奥地利': 827,\n",
       " '券商板块': 828,\n",
       " '承担': 829,\n",
       " '结婚': 830,\n",
       " '愈发': 831,\n",
       " '完备': 832,\n",
       " 'saucony': 833,\n",
       " '专注': 834,\n",
       " '二是': 835,\n",
       " '鼓励': 836,\n",
       " '长': 837,\n",
       " '保': 838,\n",
       " '新增': 839,\n",
       " '最低': 840,\n",
       " '文章': 841,\n",
       " '对外': 842,\n",
       " '移动互联网': 843,\n",
       " '现有': 844,\n",
       " '微信小程序': 845,\n",
       " '全新': 846,\n",
       " '快餐': 847,\n",
       " '找到': 848,\n",
       " '分': 849,\n",
       " '房价': 850,\n",
       " '提到': 851,\n",
       " '公布': 852,\n",
       " '证据': 853,\n",
       " '数据可视化': 854,\n",
       " '制定': 855,\n",
       " '高效': 856,\n",
       " '写': 857,\n",
       " '早': 858,\n",
       " '广州': 859,\n",
       " '明星': 860,\n",
       " '跌': 861,\n",
       " '在线': 862,\n",
       " '杭州': 863,\n",
       " '背景': 864,\n",
       " '观众': 865,\n",
       " '两种': 866,\n",
       " '角色': 867,\n",
       " '一线': 868,\n",
       " '性': 869,\n",
       " '陆续': 870,\n",
       " '即时': 871,\n",
       " '涉及': 872,\n",
       " '重废': 873,\n",
       " '50%': 874,\n",
       " '万科': 875,\n",
       " '不含税': 876,\n",
       " '生育': 877,\n",
       " '流程': 878,\n",
       " '当期': 879,\n",
       " '无论是': 880,\n",
       " '组合': 881,\n",
       " '用电量': 882,\n",
       " '笔者': 883,\n",
       " '强化': 884,\n",
       " '大牛市': 885,\n",
       " '孩子': 886,\n",
       " '钢铁行业': 887,\n",
       " '制造': 888,\n",
       " '就业': 889,\n",
       " '温度': 890,\n",
       " '告诉': 891,\n",
       " '实时': 892,\n",
       " '协议': 893,\n",
       " '调研': 894,\n",
       " '会上': 895,\n",
       " '平等': 896,\n",
       " '创造': 897,\n",
       " '长期': 898,\n",
       " '统计': 899,\n",
       " '月份': 900,\n",
       " '测量': 901,\n",
       " '同城': 902,\n",
       " '31': 903,\n",
       " '详细': 904,\n",
       " '委员会': 905,\n",
       " '前瞻性': 906,\n",
       " '意见': 907,\n",
       " '两年': 908,\n",
       " '几年': 909,\n",
       " '年代': 910,\n",
       " '上海移动': 911,\n",
       " '简称': 912,\n",
       " '净利润': 913,\n",
       " '条款': 914,\n",
       " '发行额': 915,\n",
       " '现实': 916,\n",
       " '四大': 917,\n",
       " '太': 918,\n",
       " '规则': 919,\n",
       " '教育': 920,\n",
       " '解决方案': 921,\n",
       " '总体': 922,\n",
       " '记录': 923,\n",
       " 'a股': 924,\n",
       " '农民工工资': 925,\n",
       " '发展趋势': 926,\n",
       " '原则': 927,\n",
       " '盈利模式': 928,\n",
       " '淘宝': 929,\n",
       " '无疑': 930,\n",
       " '同比': 931,\n",
       " '制造商': 932,\n",
       " '地位': 933,\n",
       " '联合': 934,\n",
       " '强大': 935,\n",
       " '众多': 936,\n",
       " '展业': 937,\n",
       " '完整': 938,\n",
       " '优秀': 939,\n",
       " '存储': 940,\n",
       " '事件': 941,\n",
       " '感觉': 942,\n",
       " '充足': 943,\n",
       " '全': 944,\n",
       " '程序': 945,\n",
       " '参加': 946,\n",
       " '先河': 947,\n",
       " '真实性': 948,\n",
       " '认可': 949,\n",
       " '约定': 950,\n",
       " '专家': 951,\n",
       " 'iphone': 952,\n",
       " '欧尚': 953,\n",
       " '人民币': 954,\n",
       " '包含': 955,\n",
       " 'p': 956,\n",
       " '分化': 957,\n",
       " '微博': 958,\n",
       " '想到': 959,\n",
       " '宣传': 960,\n",
       " 'm': 961,\n",
       " 'erp': 962,\n",
       " '库存': 963,\n",
       " '数据库': 964,\n",
       " '性能': 965,\n",
       " '至少': 966,\n",
       " '受益权': 967,\n",
       " '覆盖': 968,\n",
       " '★': 969,\n",
       " '浮动奖': 970,\n",
       " '带动': 971,\n",
       " '双': 972,\n",
       " '阿里': 973,\n",
       " '头条': 974,\n",
       " '职场': 975,\n",
       " '注销': 976,\n",
       " '优质': 977,\n",
       " '住房': 978,\n",
       " '会议': 979,\n",
       " '陕西': 980,\n",
       " '金发科技': 981,\n",
       " '提前': 982,\n",
       " '学习': 983,\n",
       " '条形码': 984,\n",
       " '补充': 985,\n",
       " '思路': 986,\n",
       " '不错': 987,\n",
       " '信号': 988,\n",
       " '额外': 989,\n",
       " '今日': 990,\n",
       " '总监': 991,\n",
       " '基础性': 992,\n",
       " '股东': 993,\n",
       " '讲': 994,\n",
       " '值得': 995,\n",
       " '反对': 996,\n",
       " '多位': 997,\n",
       " '可能会': 998,\n",
       " '有望': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordToIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reviewProcess(review, sequenceLength, wordToIndex):\n",
    "    \"\"\"\n",
    "    将数据集中的每条评论用index表示\n",
    "    wordToIndex中“pad”对应的index为0\n",
    "    \"\"\"\n",
    "\n",
    "    reviewVec = np.zeros((sequenceLength)) # 生成一个长度为1500的list\n",
    "    sequenceLen = sequenceLength  # 1500\n",
    "\n",
    "    # 判断当前的序列是否小于定义的固定序列长度\n",
    "    if len(review) < sequenceLength:\n",
    "        sequenceLen = len(review)\n",
    "\n",
    "    for i in range(sequenceLen): # 将每句话中的词用word id表示\n",
    "        if review[i] in wordToIndex:\n",
    "            reviewVec[i] = wordToIndex[review[i]]\n",
    "        else:\n",
    "            reviewVec[i] = wordToIndex[\"UNK\"] # 没有在word词典中用 UNK 表示\n",
    "\n",
    "    return reviewVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_ = []\n",
    "labels_ = []\n",
    "\n",
    "# 遍历所有的文本，将文本中的词转换成index表示\n",
    "for i in range(len(content)):\n",
    "    reviewVec = reviewProcess(content[i], 1500, wordToIndex)\n",
    "    content_.append(reviewVec)\n",
    "    labels_.append([labels[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1420.0"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_[10][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 10000)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(content_[0]), len(content_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genTrainEvalData(x, y, sequenceLength, wordToIndex, rate):\n",
    "    \"\"\"\n",
    "    生成训练集和验证集\n",
    "    \"\"\"\n",
    "\n",
    "    reviews = []\n",
    "    labels = []\n",
    "\n",
    "    # 遍历所有的文本，将文本中的词转换成index表示\n",
    "    for i in range(len(x)):\n",
    "        reviewVec = reviewProcess(x[i], sequenceLength, wordToIndex)\n",
    "        reviews.append(reviewVec)\n",
    "        labels.append([y[i]])\n",
    "\n",
    "    trainIndex = int(len(x) * rate)\n",
    "\n",
    "    trainReviews = np.asarray(reviews[:trainIndex], dtype=\"int64\")\n",
    "    trainLabels = np.array(labels[:trainIndex], dtype=\"float32\")\n",
    "\n",
    "    evalReviews = np.asarray(reviews[trainIndex:], dtype=\"int64\")\n",
    "    evalLabels = np.array(labels[trainIndex:], dtype=\"float32\")\n",
    "\n",
    "    return trainReviews, trainLabels, evalReviews, evalLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainReviews, trainLabels, evalReviews, evalLabels = genTrainEvalData(content, labels, 1500, wordToIndex, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 1500), (2000, 1500))"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainReviews.shape, evalReviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainReviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 1), (2000, 1))"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainLabels.shape, evalLabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1,     1,     1, 13234,     1,     1,     1,     1, 13234,\n",
       "           1,     1,     1,     1,     1,  5663, 22576, 12565,  5288,\n",
       "           1,     1])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainReviews[0][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出batch数据集\n",
    "\n",
    "def nextBatch(x, y, batchSize):\n",
    "        \"\"\"\n",
    "        生成batch数据集，用生成器的方式输出\n",
    "        \"\"\"\n",
    "    \n",
    "        perm = np.arange(len(x))\n",
    "        np.random.shuffle(perm)\n",
    "        x = x[perm]\n",
    "        y = y[perm]\n",
    "        \n",
    "        numBatches = len(x) // batchSize\n",
    "\n",
    "        for i in range(numBatches):\n",
    "            start = i * batchSize\n",
    "            end = start + batchSize\n",
    "            batchX = np.array(x[start: end], dtype=\"int64\")\n",
    "            batchY = np.array(y[start: end], dtype=\"float32\")\n",
    "            \n",
    "            yield batchX, batchY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成位置嵌入\n",
    "def fixedPositionEmbedding(batchSize, sequenceLen):\n",
    "    embeddedPosition = []\n",
    "    for batch in range(batchSize): # 128\n",
    "        x = []\n",
    "        # [1., 0., 0., ..., 0., 0., 0.]\n",
    "        # [0., 1., 0., ..., 0., 0., 0.]\n",
    "        for step in range(sequenceLen): # 1500\n",
    "            a = np.zeros(sequenceLen) # (1500,)\n",
    "            a[step] = 1\n",
    "            x.append(a)\n",
    "        embeddedPosition.append(x)\n",
    "    \n",
    "    return np.array(embeddedPosition, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddedPosition = fixedPositionEmbedding(128, 1500)\n",
    "embeddedPosition[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 1500, 1500)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddedPosition.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置参数\n",
    "\n",
    "class TrainingConfig(object):\n",
    "    epoches = 10\n",
    "    evaluateEvery = 100\n",
    "    checkpointEvery = 100\n",
    "    learningRate = 0.001\n",
    "    \n",
    "    \n",
    "class ModelConfig(object):\n",
    "    embeddingSize = 200\n",
    "    filters = 128  # 内层一维卷积核的数量，外层卷积核的数量应该等于embeddingSize，因为要确保每个layer后的输出维度和输入维度是一致的。\n",
    "    numHeads = 8  # Attention 的头数\n",
    "    numBlocks = 1  # 设置transformer block的数量\n",
    "    epsilon = 1e-8  # LayerNorm 层中的最小除数\n",
    "    keepProp = 0.9  # multi head attention 中的dropout\n",
    "    dropoutKeepProb = 0.5 # 全连接层的dropout\n",
    "    l2RegLambda = 0.0\n",
    "    \n",
    "    \n",
    "class Config(object):\n",
    "    embeddingSize = 200\n",
    "    sequenceLength = 1500  # 取了所有序列长度的均值\n",
    "    batchSize = 128\n",
    "    \n",
    "    dataSource = \"../data/preProcess/labeledTrain.csv\"\n",
    "    \n",
    "    stopWordSource = \"../data/english\"\n",
    "    \n",
    "    numClasses = 2\n",
    "    \n",
    "    rate = 0.8  # 训练集的比例\n",
    "    \n",
    "    training = TrainingConfig()\n",
    "    \n",
    "    model = ModelConfig()\n",
    "\n",
    "    \n",
    "# 实例化配置参数对象\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型构建\n",
    "class Transformer(object):\n",
    "    \"\"\"\n",
    "    Transformer Encoder 用于文本分类\n",
    "    \"\"\"\n",
    "    def __init__(self, config, wordEmbedding):\n",
    "\n",
    "        # 定义模型的输入\n",
    "        # [?, 1500]\n",
    "        self.inputX = tf.placeholder(tf.int32, [None, config.sequenceLength], name=\"inputX\")\n",
    "        # [?, 1]\n",
    "        self.inputY = tf.placeholder(tf.float32, [None, 1], name=\"inputY\")\n",
    "        \n",
    "        self.dropoutKeepProb = tf.placeholder(tf.float32, name=\"dropoutKeepProb\")\n",
    "        # [?, 1500, 200]\n",
    "#         self.embeddedPosition = tf.placeholder(tf.float32, [None, config.sequenceLength, config.embeddingSize], name=\"embeddedPosition\")\n",
    "        \n",
    "        self.config = config\n",
    "        \n",
    "        # 定义l2损失\n",
    "        l2Loss = tf.constant(0.0)\n",
    "        \n",
    "        # 词嵌入层, 位置向量的定义方式有两种：一是直接用固定的one-hot的形式传入，然后和词向量拼接，在当前的数据集上表现效果更好。另一种\n",
    "        # 就是按照论文中的方法实现，这样的效果反而更差，可能是增大了模型的复杂度，在小数据集上表现不佳。\n",
    "        \n",
    "#         with tf.name_scope(\"embedding\"):\n",
    "\n",
    "#             # 利用预训练的词向量初始化词嵌入矩阵\n",
    "#             # [?, 200]\n",
    "#             self.W = tf.Variable(tf.cast(wordEmbedding, dtype=tf.float32, name=\"word2vec\") ,name=\"W\")\n",
    "#             # 利用词嵌入矩阵将输入的数据中的词转换成词向量，维度[batch_size, sequence_length, embedding_size]\n",
    "#             # [?, 1500, 200]  [?, 1500] [?, 200]\n",
    "#             self.embedded = tf.nn.embedding_lookup(self.W, self.inputX)\n",
    "#             # embedding\n",
    "#             # positionEmbedding [?, 1500, 1500]\n",
    "#             self.embeddedWords = tf.concat([self.embedded, self.embeddedPosition], -1)\n",
    "\n",
    "#         with tf.name_scope(\"transformer\"):\n",
    "#             for i in range(config.model.numBlocks):\n",
    "#                 with tf.name_scope(\"transformer-{}\".format(i + 1)):\n",
    "            \n",
    "#                     # 维度[batch_size, sequence_length, embedding_size]\n",
    "#                     multiHeadAtt = self._multiheadAttention(rawKeys=self.embedded, queries=self.embeddedWords,\n",
    "#                                                             keys=self.embeddedWords)\n",
    "#                     # 维度[batch_size, sequence_length, embedding_size]\n",
    "#                     self.embeddedWords = self._feedForward(multiHeadAtt, \n",
    "#                                                            [config.model.filters, config.model.embeddingSize + config.sequenceLength])\n",
    "                \n",
    "#             outputs = tf.reshape(self.embeddedWords, [-1, config.sequenceLength * (config.model.embeddingSize + config.sequenceLength)])\n",
    "\n",
    "#         outputSize = outputs.get_shape()[-1].value\n",
    "\n",
    "        with tf.name_scope(\"wordEmbedding\"):\n",
    "            self.W = tf.Variable(tf.cast(wordEmbedding, dtype=tf.float32, name=\"word2vec\"), name=\"W\")\n",
    "            self.wordEmbedded = tf.nn.embedding_lookup(self.W, self.inputX)\n",
    "        \n",
    "        with tf.name_scope(\"positionEmbedding\"):\n",
    "            print(self.wordEmbedded)\n",
    "            self.positionEmbedded = self._positionEmbedding()\n",
    "            \n",
    "        self.embeddedWords = self.wordEmbedded + self.positionEmbedded\n",
    "            \n",
    "        with tf.name_scope(\"transformer\"):\n",
    "            for i in range(config.model.numBlocks):\n",
    "                with tf.name_scope(\"transformer-{}\".format(i + 1)):\n",
    "            \n",
    "                    # 维度[batch_size, sequence_length, embedding_size]\n",
    "                    multiHeadAtt = self._multiheadAttention(rawKeys=self.wordEmbedded, queries=self.embeddedWords,\n",
    "                                                            keys=self.embeddedWords)\n",
    "                    # 维度[batch_size, sequence_length, embedding_size]\n",
    "                    self.embeddedWords = self._feedForward(multiHeadAtt, [config.model.filters, config.model.embeddingSize])\n",
    "                \n",
    "            outputs = tf.reshape(self.embeddedWords, [-1, config.sequenceLength * (config.model.embeddingSize)])\n",
    "\n",
    "        outputSize = outputs.get_shape()[-1].value\n",
    "        \n",
    "        with tf.name_scope(\"dropout\"):\n",
    "            outputs = tf.nn.dropout(outputs, keep_prob=self.dropoutKeepProb)\n",
    "    \n",
    "        # 全连接层的输出\n",
    "        with tf.name_scope(\"output\"):\n",
    "            outputW = tf.get_variable(\n",
    "                \"outputW\",\n",
    "                shape=[outputSize, 1],\n",
    "                initializer=tf.contrib.layers.xavier_initializer())\n",
    "            \n",
    "            outputB= tf.Variable(tf.constant(0.1, shape=[1]), name=\"outputB\")\n",
    "            l2Loss += tf.nn.l2_loss(outputW)\n",
    "            l2Loss += tf.nn.l2_loss(outputB)\n",
    "            self.predictions = tf.nn.xw_plus_b(outputs, outputW, outputB, name=\"predictions\")\n",
    "            self.binaryPreds = tf.cast(tf.greater_equal(self.predictions, 0.5), tf.float32, name=\"binaryPreds\")\n",
    "        \n",
    "        # 计算二元交叉熵损失\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            \n",
    "            losses = tf.nn.sigmoid_cross_entropy_with_logits(logits=self.predictions, labels=self.inputY)\n",
    "            self.loss = tf.reduce_mean(losses) + config.model.l2RegLambda * l2Loss\n",
    "            \n",
    "    def _layerNormalization(self, inputs, scope=\"layerNorm\"):\n",
    "        # LayerNorm层和BN层有所不同\n",
    "        epsilon = self.config.model.epsilon\n",
    "\n",
    "        inputsShape = inputs.get_shape() # [batch_size, sequence_length, embedding_size]\n",
    "\n",
    "        paramsShape = inputsShape[-1:]\n",
    "\n",
    "        # LayerNorm是在最后的维度上计算输入的数据的均值和方差，BN层是考虑所有维度的\n",
    "        # mean, variance的维度都是[batch_size, sequence_len, 1]\n",
    "        mean, variance = tf.nn.moments(inputs, [-1], keep_dims=True)\n",
    "\n",
    "        beta = tf.Variable(tf.zeros(paramsShape))\n",
    "\n",
    "        gamma = tf.Variable(tf.ones(paramsShape))\n",
    "        normalized = (inputs - mean) / ((variance + epsilon) ** .5)\n",
    "        \n",
    "        outputs = gamma * normalized + beta\n",
    "\n",
    "        return outputs\n",
    "    # rawKeys=self.embedded, queries=self.embeddedWords, keys=self.embeddedWords        \n",
    "    def _multiheadAttention(self, rawKeys, queries, keys, numUnits=None, causality=False, scope=\"multiheadAttention\"):\n",
    "        # rawKeys 的作用是为了计算mask时用的，因为keys是加上了position embedding的，其中不存在padding为0的值\n",
    "        \n",
    "        numHeads = self.config.model.numHeads # 8\n",
    "        keepProp = self.config.model.keepProp\n",
    "        \n",
    "        if numUnits is None:  # 若是没传入值，直接去输入数据的最后一维，即embedding size.\n",
    "            numUnits = queries.get_shape().as_list()[-1]\n",
    "\n",
    "        # tf.layers.dense可以做多维tensor数据的非线性映射，在计算self-Attention时，一定要对这三个值进行非线性映射，\n",
    "        # 其实这一步就是论文中Multi-Head Attention中的对分割后的数据进行权重映射的步骤，我们在这里先映射后分割，原则上是一样的。\n",
    "        # Q, K, V的维度都是[batch_size, sequence_length, embedding_size]\n",
    "        Q = tf.layers.dense(queries, numUnits, activation=tf.nn.relu)\n",
    "        K = tf.layers.dense(keys, numUnits, activation=tf.nn.relu)\n",
    "        V = tf.layers.dense(keys, numUnits, activation=tf.nn.relu)\n",
    "\n",
    "        # 将数据按最后一维分割成num_heads个, 然后按照第一维拼接\n",
    "        # Q, K, V 的维度都是[batch_size * numHeads, sequence_length, embedding_size/numHeads]\n",
    "        Q_ = tf.concat(tf.split(Q, numHeads, axis=-1), axis=0) \n",
    "        K_ = tf.concat(tf.split(K, numHeads, axis=-1), axis=0) \n",
    "        V_ = tf.concat(tf.split(V, numHeads, axis=-1), axis=0)\n",
    "\n",
    "        # 计算keys和queries之间的点积，维度[batch_size * numHeads, queries_len, key_len], 后两维是queries和keys的序列长度\n",
    "        similary = tf.matmul(Q_, tf.transpose(K_, [0, 2, 1]))\n",
    "\n",
    "        # 对计算的点积进行缩放处理，除以向量长度的根号值\n",
    "        scaledSimilary = similary / (K_.get_shape().as_list()[-1] ** 0.5)\n",
    "\n",
    "        # 在我们输入的序列中会存在padding这个样的填充词，这种词应该对最终的结果是毫无帮助的，原则上说当padding都是输入0时，\n",
    "        # 计算出来的权重应该也是0，但是在transformer中引入了位置向量，当和位置向量相加之后，其值就不为0了，因此在添加位置向量\n",
    "        # 之前，我们需要将其mask为0。虽然在queries中也存在这样的填充词，但原则上模型的结果之和输入有关，而且在self-Attention中\n",
    "        # queryies = keys，因此只要一方为0，计算出的权重就为0。\n",
    "        # 具体关于key mask的介绍可以看看这里： https://github.com/Kyubyong/transformer/issues/3\n",
    "        \n",
    "#         因为训练时基本是使用mini batch的方式，这就需要对token数量较少的sequence用<PAD>在尾部填充使得batch里的每个句子长度相同\n",
    "#         在Encoder环节去除<PAD>对句子中其他token的影响是在Scaled Dot-Product 结束后紧跟一个mask操作（\n",
    "#         即对<PAD>的score减去一个极大值---e.g. 1E+9，使得softmax输出的<PAD>token的相关性系数接近 0）\n",
    "\n",
    "#         对于没有<PAD>填充的句子则Mask操作就可以忽略，所以Mask操作是optional的\n",
    "\n",
    "#         笔者个人感性理解Encoder里的mask操作：即保证<PAD>token在提炼过程中：\n",
    "#         <PAD>不会对其他token向量的信息提炼产生影响\n",
    "#         对<PAD>向量再怎么信息提炼还是<PAD>向量\n",
    "\n",
    "        # 将每一时序上的向量中的值相加取平均值\n",
    "        keyMasks = tf.sign(tf.abs(tf.reduce_sum(rawKeys, axis=-1)))  # 维度[batch_size, time_step]\n",
    "\n",
    "        # 利用tf，tile进行张量扩张， 维度[batch_size * numHeads, keys_len] keys_len = keys 的序列长度\n",
    "        keyMasks = tf.tile(keyMasks, [numHeads, 1]) \n",
    "\n",
    "        # 增加一个维度，并进行扩张，得到维度[batch_size * numHeads, queries_len, keys_len]\n",
    "        keyMasks = tf.tile(tf.expand_dims(keyMasks, 1), [1, tf.shape(queries)[1], 1])\n",
    "\n",
    "        # tf.ones_like生成元素全为1，维度和scaledSimilary相同的tensor, 然后得到负无穷大的值\n",
    "        paddings = tf.ones_like(scaledSimilary) * (-2 ** (32 + 1))\n",
    "\n",
    "        # tf.where(condition, x, y),condition中的元素为bool值，其中对应的True用x中的元素替换，对应的False用y中的元素替换\n",
    "        # 因此condition,x,y的维度是一样的。下面就是keyMasks中的值为0就用paddings中的值替换\n",
    "        maskedSimilary = tf.where(tf.equal(keyMasks, 0), paddings, scaledSimilary) # 维度[batch_size * numHeads, queries_len, key_len]\n",
    "\n",
    "        # 在计算当前的词时，只考虑上文，不考虑下文，出现在Transformer Decoder中。在文本分类时，可以只用Transformer Encoder。\n",
    "        # Decoder是生成模型，主要用在语言生成中\n",
    "        if causality:\n",
    "            diagVals = tf.ones_like(maskedSimilary[0, :, :])  # [queries_len, keys_len]\n",
    "            tril = tf.contrib.linalg.LinearOperatorTriL(diagVals).to_dense()  # [queries_len, keys_len]\n",
    "            masks = tf.tile(tf.expand_dims(tril, 0), [tf.shape(maskedSimilary)[0], 1, 1])  # [batch_size * numHeads, queries_len, keys_len]\n",
    "\n",
    "            paddings = tf.ones_like(masks) * (-2 ** (32 + 1))\n",
    "            maskedSimilary = tf.where(tf.equal(masks, 0), paddings, maskedSimilary)  # [batch_size * numHeads, queries_len, keys_len]\n",
    "\n",
    "        # 通过softmax计算权重系数，维度 [batch_size * numHeads, queries_len, keys_len]\n",
    "        weights = tf.nn.softmax(maskedSimilary)\n",
    "\n",
    "        # 加权和得到输出值, 维度[batch_size * numHeads, sequence_length, embedding_size/numHeads]\n",
    "        outputs = tf.matmul(weights, V_)\n",
    "\n",
    "        # 将多头Attention计算的得到的输出重组成最初的维度[batch_size, sequence_length, embedding_size]\n",
    "        outputs = tf.concat(tf.split(outputs, numHeads, axis=0), axis=2)\n",
    "        \n",
    "        outputs = tf.nn.dropout(outputs, keep_prob=keepProp)\n",
    "\n",
    "        # 对每个subLayers建立残差连接，即H(x) = F(x) + x\n",
    "        outputs += queries\n",
    "        # normalization 层\n",
    "        outputs = self._layerNormalization(outputs)\n",
    "        return outputs\n",
    "\n",
    "    # multiHeadAtt, [config.model.filters, config.model.embeddingSize]\n",
    "    def _feedForward(self, inputs, filters, scope=\"multiheadAttention\"):\n",
    "        # 在这里的前向传播采用卷积神经网络\n",
    "        \n",
    "        # 内层\n",
    "        params = {\"inputs\": inputs, \"filters\": filters[0], \"kernel_size\": 1,\n",
    "                  \"activation\": tf.nn.relu, \"use_bias\": True}\n",
    "        outputs = tf.layers.conv1d(**params)\n",
    "\n",
    "        # 外层\n",
    "        params = {\"inputs\": outputs, \"filters\": filters[1], \"kernel_size\": 1,\n",
    "                  \"activation\": None, \"use_bias\": True}\n",
    "\n",
    "        # 这里用到了一维卷积，实际上卷积核尺寸还是二维的，只是只需要指定高度，宽度和embedding size的尺寸一致\n",
    "        # 维度[batch_size, sequence_length, embedding_size]\n",
    "        outputs = tf.layers.conv1d(**params)\n",
    "\n",
    "        # 残差连接\n",
    "        outputs += inputs\n",
    "\n",
    "        # 归一化处理\n",
    "        outputs = self._layerNormalization(outputs)\n",
    "\n",
    "        return outputs\n",
    "    \n",
    "    def _positionEmbedding(self, scope=\"positionEmbedding\"):\n",
    "        # 生成可训练的位置向量\n",
    "        batchSize = self.config.batchSize\n",
    "        sequenceLen = self.config.sequenceLength\n",
    "        embeddingSize = self.config.model.embeddingSize\n",
    "        \n",
    "        # 生成位置的索引，并扩张到batch中所有的样本上\n",
    "        positionIndex = tf.tile(tf.expand_dims(tf.range(sequenceLen), 0), [batchSize, 1])\n",
    "        \n",
    "        # 根据正弦和余弦函数来获得每个位置上的embedding的第一部分\n",
    "        positionEmbedding = np.array([[pos / np.power(10000, (i-i%2) / embeddingSize) for i in range(embeddingSize)] \n",
    "                                      for pos in range(sequenceLen)])\n",
    "\n",
    "        # 然后根据奇偶性分别用sin和cos函数来包装\n",
    "        positionEmbedding[:, 0::2] = np.sin(positionEmbedding[:, 0::2])\n",
    "        positionEmbedding[:, 1::2] = np.cos(positionEmbedding[:, 1::2])\n",
    "\n",
    "        # 将positionEmbedding转换成tensor的格式\n",
    "        positionEmbedding_ = tf.cast(positionEmbedding, dtype=tf.float32)\n",
    "\n",
    "        # 得到三维的矩阵[batchSize, sequenceLen, embeddingSize]\n",
    "        positionEmbedded = tf.nn.embedding_lookup(positionEmbedding_, positionIndex)\n",
    "\n",
    "        return positionEmbedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _positionEmbedding(config):\n",
    "    # 生成可训练的位置向量\n",
    "    batchSize = config.batchSize\n",
    "    sequenceLen = config.sequenceLength\n",
    "    embeddingSize = config.model.embeddingSize\n",
    "\n",
    "    # 生成位置的索引，并扩张到batch中所有的样本上\n",
    "    positionIndex = tf.tile(tf.expand_dims(tf.range(sequenceLen), 0), [batchSize, 1])\n",
    "\n",
    "    # 根据正弦和余弦函数来获得每个位置上的embedding的第一部分\n",
    "    positionEmbedding = np.array([[pos / np.power(10000, (i-i%2) / embeddingSize) for i in range(embeddingSize)] \n",
    "                                  for pos in range(sequenceLen)])\n",
    "\n",
    "    # 然后根据奇偶性分别用sin和cos函数来包装\n",
    "    positionEmbedding[:, 0::2] = np.sin(positionEmbedding[:, 0::2])\n",
    "    positionEmbedding[:, 1::2] = np.cos(positionEmbedding[:, 1::2])\n",
    "\n",
    "    # 将positionEmbedding转换成tensor的格式\n",
    "    positionEmbedding_ = tf.cast(positionEmbedding, dtype=tf.float32)\n",
    "\n",
    "    # 得到三维的矩阵[batchSize, sequenceLen, embeddingSize]\n",
    "    positionEmbedded = tf.nn.embedding_lookup(positionEmbedding_, positionIndex)\n",
    "\n",
    "    return positionEmbedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义性能指标函数\n",
    "\n",
    "def mean(item):\n",
    "    return sum(item) / len(item)\n",
    "\n",
    "\n",
    "def genMetrics(trueY, predY, binaryPredY):\n",
    "    \"\"\"\n",
    "    生成acc和auc值\n",
    "    \"\"\"\n",
    "    auc = roc_auc_score(trueY, predY)\n",
    "    accuracy = accuracy_score(trueY, binaryPredY)\n",
    "    precision = precision_score(trueY, binaryPredY)\n",
    "    recall = recall_score(trueY, binaryPredY)\n",
    "    \n",
    "    return round(accuracy, 4), round(auc, 4), round(precision, 4), round(recall, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(128), Dimension(1500), Dimension(200)])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positionEmbedded = _positionEmbedding(config)\n",
    "positionEmbedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"wordEmbedding/embedding_lookup/Identity:0\", shape=(?, 1500, 200), dtype=float32)\n",
      "INFO:tensorflow:Summary name wordEmbedding/W:0/grad/hist is illegal; using wordEmbedding/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name wordEmbedding/W:0/grad/sparsity is illegal; using wordEmbedding/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name dense/kernel:0/grad/hist is illegal; using dense/kernel_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name dense/kernel:0/grad/sparsity is illegal; using dense/kernel_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name dense/bias:0/grad/hist is illegal; using dense/bias_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name dense/bias:0/grad/sparsity is illegal; using dense/bias_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name dense_1/kernel:0/grad/hist is illegal; using dense_1/kernel_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name dense_1/kernel:0/grad/sparsity is illegal; using dense_1/kernel_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name dense_1/bias:0/grad/hist is illegal; using dense_1/bias_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name dense_1/bias:0/grad/sparsity is illegal; using dense_1/bias_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name dense_2/kernel:0/grad/hist is illegal; using dense_2/kernel_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name dense_2/kernel:0/grad/sparsity is illegal; using dense_2/kernel_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name dense_2/bias:0/grad/hist is illegal; using dense_2/bias_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name dense_2/bias:0/grad/sparsity is illegal; using dense_2/bias_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name transformer/transformer-1/Variable:0/grad/hist is illegal; using transformer/transformer-1/Variable_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name transformer/transformer-1/Variable:0/grad/sparsity is illegal; using transformer/transformer-1/Variable_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name transformer/transformer-1/Variable_1:0/grad/hist is illegal; using transformer/transformer-1/Variable_1_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name transformer/transformer-1/Variable_1:0/grad/sparsity is illegal; using transformer/transformer-1/Variable_1_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv1d/kernel:0/grad/hist is illegal; using conv1d/kernel_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv1d/kernel:0/grad/sparsity is illegal; using conv1d/kernel_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv1d/bias:0/grad/hist is illegal; using conv1d/bias_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv1d/bias:0/grad/sparsity is illegal; using conv1d/bias_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv1d_1/kernel:0/grad/hist is illegal; using conv1d_1/kernel_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv1d_1/kernel:0/grad/sparsity is illegal; using conv1d_1/kernel_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv1d_1/bias:0/grad/hist is illegal; using conv1d_1/bias_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv1d_1/bias:0/grad/sparsity is illegal; using conv1d_1/bias_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name transformer/transformer-1/Variable_2:0/grad/hist is illegal; using transformer/transformer-1/Variable_2_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name transformer/transformer-1/Variable_2:0/grad/sparsity is illegal; using transformer/transformer-1/Variable_2_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name transformer/transformer-1/Variable_3:0/grad/hist is illegal; using transformer/transformer-1/Variable_3_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name transformer/transformer-1/Variable_3:0/grad/sparsity is illegal; using transformer/transformer-1/Variable_3_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name outputW:0/grad/hist is illegal; using outputW_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name outputW:0/grad/sparsity is illegal; using outputW_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name output/outputB:0/grad/hist is illegal; using output/outputB_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name output/outputB:0/grad/sparsity is illegal; using output/outputB_0/grad/sparsity instead.\n",
      "Writing to /Users/dali/Downloads/搜狐内容识别算法大赛/notebook/summarys\n",
      "\n",
      "start training model\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "\n",
    "# 生成训练集和验证集\n",
    "# trainReviews = data.trainReviews\n",
    "# trainLabels = data.trainLabels\n",
    "# evalReviews = data.evalReviews\n",
    "# evalLabels = data.evalLabels\n",
    "\n",
    "# wordEmbedding = data.wordEmbedding\n",
    "\n",
    "# positionEmbedded = _positionEmbedding(config)\n",
    "\n",
    "# 定义计算图\n",
    "with tf.Graph().as_default():\n",
    "\n",
    "    session_conf = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\n",
    "    session_conf.gpu_options.allow_growth=True\n",
    "    session_conf.gpu_options.per_process_gpu_memory_fraction = 0.9  # 配置gpu占用率  \n",
    "\n",
    "    sess = tf.Session(config=session_conf)\n",
    "    \n",
    "    # 定义会话\n",
    "    with sess.as_default():\n",
    "        transformer = Transformer(config, wordEmbedding)\n",
    "        \n",
    "        globalStep = tf.Variable(0, name=\"globalStep\", trainable=False)\n",
    "        # 定义优化函数，传入学习速率参数\n",
    "        optimizer = tf.train.AdamOptimizer(config.training.learningRate)\n",
    "        # 计算梯度,得到梯度和变量\n",
    "        gradsAndVars = optimizer.compute_gradients(transformer.loss)\n",
    "        # 将梯度应用到变量下，生成训练器\n",
    "        trainOp = optimizer.apply_gradients(gradsAndVars, global_step=globalStep)\n",
    "        \n",
    "        # 用summary绘制tensorBoard\n",
    "        gradSummaries = []\n",
    "        for g, v in gradsAndVars:\n",
    "            if g is not None:\n",
    "                tf.summary.histogram(\"{}/grad/hist\".format(v.name), g)\n",
    "                tf.summary.scalar(\"{}/grad/sparsity\".format(v.name), tf.nn.zero_fraction(g))\n",
    "        \n",
    "        outDir = os.path.abspath(os.path.join(os.path.curdir, \"summarys\"))\n",
    "        print(\"Writing to {}\\n\".format(outDir))\n",
    "        \n",
    "        lossSummary = tf.summary.scalar(\"loss\", transformer.loss)\n",
    "        summaryOp = tf.summary.merge_all()\n",
    "        \n",
    "        trainSummaryDir = os.path.join(outDir, \"train\")\n",
    "        trainSummaryWriter = tf.summary.FileWriter(trainSummaryDir, sess.graph)\n",
    "        \n",
    "        evalSummaryDir = os.path.join(outDir, \"eval\")\n",
    "        evalSummaryWriter = tf.summary.FileWriter(evalSummaryDir, sess.graph)\n",
    "        \n",
    "        \n",
    "        # 初始化所有变量\n",
    "        saver = tf.train.Saver(tf.global_variables(), max_to_keep=5)\n",
    "        \n",
    "        # 保存模型的一种方式，保存为pb文件\n",
    "#         builder = tf.saved_model.builder.SavedModelBuilder(\"../model/Transformer/savedModel\")\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        def trainStep(batchX, batchY):\n",
    "            \"\"\"\n",
    "            训练函数\n",
    "            \"\"\"   \n",
    "            feed_dict = {\n",
    "              transformer.inputX: batchX,\n",
    "              transformer.inputY: batchY,\n",
    "              transformer.dropoutKeepProb: config.model.dropoutKeepProb\n",
    "            }\n",
    "            _, summary, step, loss, predictions, binaryPreds = sess.run(\n",
    "                [trainOp, summaryOp, globalStep, transformer.loss, transformer.predictions, transformer.binaryPreds],\n",
    "                feed_dict)\n",
    "            timeStr = datetime.datetime.now().isoformat()\n",
    "            acc,es = []\n",
    "            accs = []\n",
    "            aucs = []\n",
    "            precisions = []\n",
    "            recalls = []\n",
    "\n",
    "            for batchEval in nextBatch(evalReviews, evalLabels, config.batchSize):\n",
    "                loss, acc, auc, precision, recall = devStep(batchEval[0], batchEval[1])\n",
    "                losses.append(loss)\n",
    "                accs.append(acc)\n",
    "                aucs.append(auc)\n",
    "                precisions.append(precision)\n",
    "                recalls.append(recall)\n",
    "\n",
    "            time_str = datetime.datetime.now().isoformat()\n",
    "            print(\"{}, step: {}, loss: {}, acc: {}, auc: {}, precision: {}, recall: {}\".format(time_str, currentStep, mean(losses), \n",
    "                                                                                               mean(accs), mean(aucs), mean(precisions),\n",
    "                                                                                               mean(recalls)))\n",
    "\n",
    "            if currentStep % config.training.checkpointEvery == 0:\n",
    "                # 保存模型的另一种方法，保存checkpoint文件\n",
    "                path = saver.save(sess, \"../model/Transformer/model/my-model\", global_step=currentStep)\n",
    "                print(\"Saved model checkpoint to {}\\n\".format(path))\n",
    "\n",
    "            auc, precision, recall = genMetrics(batchY, predictions, binaryPreds)\n",
    "            print(\"{}, step: {}, loss: {}, acc: {}, auc: {}, precision: {}, recall: {}\".format(timeStr, step, loss, acc, auc, precision, recall))\n",
    "            trainSummaryWriter.add_summary(summary, step)\n",
    "\n",
    "    def devStep(batchX, batchY):\n",
    "        \"\"\"\n",
    "        验证函数\n",
    "        \"\"\"\n",
    "        feed_dict = {\n",
    "          transformer.inputX: batchX,\n",
    "          transformer.inputY: batchY,\n",
    "          transformer.dropoutKeepProb: 1.0\n",
    "        }\n",
    "        summary, step, loss, predictions, binaryPreds = sess.run(\n",
    "            [summaryOp, globalStep, transformer.loss, transformer.predictions, transformer.binaryPreds],\n",
    "            feed_dict)\n",
    "\n",
    "        acc, auc, precision, recall = genMetrics(batchY, predictions, binaryPreds)\n",
    "\n",
    "        evalSummaryWriter.add_summary(summary, step)\n",
    "\n",
    "        return loss, acc, auc, precision, recall\n",
    "\n",
    "    for i in range(config.training.epoches):\n",
    "        # 训练模型\n",
    "        print(\"start training model\")\n",
    "        for batchTrain in nextBatch(trainReviews, trainLabels, config.batchSize):\n",
    "            trainStep(batchTrain[0], batchTrain[1])\n",
    "\n",
    "            currentStep = tf.train.global_step(sess, globalStep) \n",
    "            if currentStep % config.training.evaluateEvery == 0:\n",
    "                print(\"\\n Evaluation:\")\n",
    "\n",
    "                lossinputs = {\"inputX\": tf.saved_model.utils.build_tensor_info(transformer.inputX),\n",
    "                  \"keepProb\": tf.saved_model.utils.build_tensor_info(transformer.dropoutKeepProb)}\n",
    "\n",
    "        outputs = {\"binaryPreds\": tf.saved_model.utils.build_tensor_info(transformer.binaryPreds)}\n",
    "\n",
    "        prediction_signature = tf.saved_model.signature_def_utils.build_signature_def(inputs=inputs, outputs=outputs,\n",
    "                                                                                      method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME)\n",
    "        legacy_init_op = tf.group(tf.tables_initializer(), name=\"legacy_init_op\")\n",
    "        builder.add_meta_graph_and_variables(sess, [tf.saved_model.tag_constants.SERVING],\n",
    "                                            signature_def_map={\"predict\": prediction_signature}, legacy_init_op=legacy_init_op)\n",
    "\n",
    "        builder.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
